Bret 0:00
Hey folks read here. I am sitting with someone, most of the people who follow me, almost certainly know. But for those who don't, this is Benjamin Boyce. Benjamin has been chronicling what has been going on at evergreen since the debacle in spring of 2017. He and I did not know each other before, but Benjamin is an alum of evergreen, I was teaching there, and we've become friends in the aftermath of that event. So anyway, we are here to talk on what will soon be the set of Brett Weinstein is dark horse podcast, we are here to talk about what is taking place with you. With Google with the recent recent revelations out of Project Veritas. Do you want to say something about what you've been up to and what you've experienced recently at the hands of Google?

Unknown 0:52
Well, let's back up a little bit. So I've been working on the story about evergreen, which includes you, but I've gone beyond the Brett Weinstein story into various layers of student activism and student counter activism and then the administration and the faculty and, and I've been following this for now two years. And I've kind of it's kind of obvious to me that I might be kind of annoying for certain people within the institution of the Evergreen State College, because I keep on bringing to light things that they very explicitly don't want to be brought to light. However, they are a public institution. And Washington state law has a very explicit public records, set of statutes. So they owe me information, they owe the public information. And I've been able to get information even though they've been basically obstructing my access through official means the public records department is basically locked at a standstill, so I get information from other places.

Bret 1:59
But wait, I want to stop you right there. Because I think this is an incredibly important fact that the public doesn't know, which is that this public institution is by all evidence conspiring against the laws of the state of Washington, it is obstructing your attempt to get information that you are legally entitled to get from the institution, and it's giving you the runaround. So that raises serious questions about an institution that has problems that have been revealed through public records requests. So effectively, the institution has gone rogue, and surely there is some legal mechanism that should kick in, that forces them to comply, because the mechanism that keeps them honest, is people like you or me taking information that we are able to extract and exposing it and discussing it and letting the chips fall where they may.

Benjamin Boyce 2:53
Well add to that the fact that evergreens enrollment is tanking, and their main source of revenue right now is the legislator and the only thing that they can legislate Sure. legislature, the legislature, yeah, just a governing body, the governing body full of legislators, yes. And they have the one proud thing that evergreen can tout as a win is getting securing funding from the legislature. They are getting state money in order to survive. Therefore, it compounds that the problematics of why would they not be following the letter of the state law or even the spirit of the law? Why would they be wanting to take money, but not giving anything back in return? It seems like a quid pro quo. If you are a public servant, then you are beholden to the public. Yeah. And the law is the law and the legislature should surely be holding them to the laws of the state of Washington, and presumably withholding funds. If they don't comply. I would also say that the instruction not to comply must have come from somewhere and I think you and I would be likely to guess the same source. Yeah. George has been all about spin and President bridges. Yeah, yes. George bridges

Bret 4:14
and current president current president bridges, oddly not fired after one of the most amazing shows of incompetence anyone has ever seen on American college. Well, at least live streamed? Yeah, well, that's for sure. But let's just say we don't have evidence for greater incompetence shown by other college presidents that I'm aware of this is really singular, and yet the man retains his job.

Benjamin Boyce 4:40
So what brings it up to an intersection my work on evergreen intersecting with this Project Veritas revelation about the way that Google is, we've already known that Google has a hand at controlling information. That should be pretty much obvious, but this makes it very explicit. A couple of weeks ago, I got demonetised. No, last Tuesday, I got demonetised about 40 videos in the last six months where all of a sudden, well,

Bret 5:10
I don't want to quibble here, but I think we have to be super careful. You were soft D monetized softmod, which I wasn't even aware, what's the thing, but apparently, a monetized video can exist at different levels of monetization, and a bunch of your videos suddenly dropped from the green state to the yellow state. Thanks for correcting. And you have inquired from Yeah, I

Benjamin Boyce 5:31
inquired into it. And I was told that I need to have all those videos manually reviewed, and I've sent submitted all those videos to manual review. And most of them are getting flipped back into the green. But more interesting to me, this caused me to look at the Google search. And I just typed in evergreens, evergreen college, and Evergreen State College. And I've repeated this a couple times now. And I know everybody has a different result. So it might be because I'm in the area of evergreen that they're straining it for some reason. But my videos of which I have 92, about the Evergreen State College. And most of those videos are based entirely on fact, and what's not based on fact is me responding or processing what these documents say. But it's all based on public records on primary sources. It's a major source of material for every documentarian that comes in does the Evergreen story, they contact me because I have all the information and the contacts. So I'm the basis for any story about evergreen, I mean, the main basis, and I am no longer listed in the video tab on Google search results, you

Bret 6:43
have become hard to find, yeah, in fact, if you use Google to search for you, which I find amazing. On the other hand, there's something I hear you, I would say you're working too hard. What you're saying about the difficulty finding you is very disturbing. But in light of what's come out of Project Veritas in the last couple days, I think there's a very interesting interpretation, which is that machine learning is being employed by Google, in order to create what they were calling fairness, which is much like equity is the inverse of what we would normally assume that term means fairness is the inverse of what we would normally assume that term means when deployed by Google. But the idea that a bunch of your videos suddenly got shifted, and then manual review is restoring them, opens the possibility that what happened is that the machine learning algorithm, whether it was sent to look at your stuff, or whether it finally got around to it, or whether somebody changed a parameter, and that's what caused your videos to be altered in their state. Somehow, some thing inside Google did a lot of thinking for the public and decided that your stuff, which is very interesting, and clearly to many who are paying attention to the story should disappear. And the idea that that can happen ought to frighten us because as you point out, what you do is really just expose the facts of the situation. You're not hostile to evergreen, I know from many conversations with you, some of them on camera, and some of them not, that you and I and Heather, all share a desire to see the institution right itself and restore the model that we know can be so successful at educating students. So the fact is, the public has every reason to want to look at your content, because the critique that you're leveling at this institution is actually in the hope of making the institution restoring it to its former glory, making it better in the future serving students. And the idea that some algorithm might think that it knows best what people should hear about evergreen, and that somehow you're off limits based on I don't know what Project Veritas suggested was that they're using some kind of analysis of language algorithm that searches for terms and decides what might be conservative of all things. It's just it's out of control.

Benjamin Boyce 9:19
Well, I don't know if this is more or less disturbing. But could it also be the case that some third party that was hired by evergreen to boost their reputation on the web, used a trick to get me listed somehow as an untrustworthy news source. So Google then automatically scrubbed me because I was told somehow I was flagged somehow?

Bret 9:41
Well, let's, let's try that a different way. Let's say to the extent that there is some algorithm out there making decisions that have big consequences, not only for your ability to earn but for the ability of the public to find information that that algorithm the existence of it creates an opportunity For agents on the other side to game. So if there is an algorithm, then there's a question of Well, what do I have to do to trigger that algorithm to make my detractors content obscure? And some time ago, I tweeted the question, I can't find it on Twitter. I don't remember exactly what phraseology I use, but the question was approximately, if it is possible to pay Twitter or some other platform to promote your content, what is to stop those platforms from selling the right to downregulate, your, your competitors content or your detractors content? And I think that's where we are.

Benjamin Boyce 10:44
Well, we are there and we just watched the Project Veritas video, and one of the questions I wanted to ask you about that, is that if you, if any one of us is given the power to shape the world, such as Google has the power to shape the world. To quote Tim Poole, would it not be a sin to not try to shape the world for the better is this not something that is inevitable that somebody given this much power is going to want to manipulate reality or perception in order to manipulate reality?

Bret 11:14
Well, I think it is inevitable if you don't build some sort of protection into the system. And one of the things that I find very surprising about the present moment, is that lots of people are losing touch with why we have counterintuitive rights, like the right to free speech. After all, we should all be able to agree that certain things that people say are just terrible, and it would be great if nobody ever said them again, right? We don't need more Nazi garbage. But there's a reason that the Constitution itself says actually even that is protected. And the reason that is protected is because there is no way to draw a line that protects heterodox speech, and bars. Truly obnoxious speech. And because we can't draw that line surgically, the value of heterodox speech is so great. And the founders were so clear on its importance, that they put in a protection against governmental interference interference with such speech. Now, unfortunately, the founders did not see the present moment, they could not I mean, these are people who never saw a bicycle and never saw a chainsaw train. They didn't have any idea what world we will be living in, they would have no way of imagining a an entity like Google that sat as an interface, a literal interface between human beings at a mechanistic level that something that has some kind of crude intelligence, could be making decisions about what I am able to say and who gets to hear it and how likely they are to encounter it. The founders would never have seen that coming in because they didn't. They didn't properly fear, private interference with speech. So the first amendment is just what I said the Congress's it's inadequate to protect the right that the founders were attempting to protect, which is the free exchange of ideas. So

Benjamin Boyce 13:11
are you advocating that the government expand its reach in order to give more Liberty Liberty like control like a well liberal tea in order to

Bret 13:20
as a liberal, there's nothing I like better than governmental control, the more of it that we have, the happier I am as basically where that falls out. Now, look, I've said many times that the problem with much liberal thought is that it underrate the danger of solution making and that as you make solutions, you are always inviting unintended consequences, and that liberals have a blind spot about those things. So Believe me, I have lots of fear about what happens if we attempt to regulate our way out of this puzzle, we could make things worse. And so I also believe, we need to recognize that we are generally just across the board, we are in novel circumstances where the documents that we were handed that built this flawed, but great nation are going to find themselves without the ability to address the problems that we encounter. And that means that we have to figure out what to do about that. Do you open up a constitutional convention? Well, I happen to think that would be a disaster if you did it. So I'm not in favor of a constitution. What

Benjamin Boyce 14:34
do you mean, why would it be a disaster? And what do you envision this convocation to be like,

Bret 14:39
well, if you open the Constitutional Convention, suddenly the immense potential to shift the nature of the republic in favor of one constituency or another would be on the table and I don't see the wisdom available to us to do it in a way that would not be detrimental. And what I do see is a lot of powerful players who would not resist the opportunity to attempt to remake the nation to their interests. So I don't favor that sort of thing. But I do favor us thinking about the fact that we have a general problem with the novelty of our of our systems relative to the documents that are built to protect us. And we have to have a frank conversation about what to do about that,

Benjamin Boyce 15:29
well, if these companies are so big and so important to anybody who creates content, Twitter is absolutely essential for me to interface with other thinkers and my audience and grow my base, and then also figure out and grow as a content creator. YouTube has been wonderful for me. evergreen was very good for me. YouTube's been wonderful for me, it's it's given me a voice, it's given me contact that I've never imagined was possible. So within these frameworks, is it possible to change them? Is it possible to band together to get people to outcry? It doesn't seem to work? Maybe Congress will go after them at some point, do we have to reboot everything or we

Bret 16:14
can't reboot everything? So I'm, unfortunately not quite ready to talk about this publicly yet. But I will say I think this is the core question that we face, which is how exactly do you deal with a mechanism as complex as civilization has become? How do you upgrade it without taking it offline, or allowing it to collapse or any of the things that we can't afford? And I do think there is a category of answers to this question. And the question about what to do about the net is, I think going to be the first test case, question is the net is new enough. And the mechanisms by which we might upgrade it so that it did not become a totalitarian nightmare. Those mechanisms actually exist at our disposal if we can think I'd use a cliche but think outside the box enough to deploy them intelligently. We have seen enough components that are available to us that actually, we the public can upgrade the net, without asking permission to do it. Okay. Right. We can effectively out compete the authoritarians in their own landscape.

Benjamin Boyce 17:35
That sounds like a technical solution. Do you have any ideas about a cultural solution, the way that we interact with one another the kind of content that we train ourselves to favor or the types of interactions that we promote or demote inside of ourselves that might be playing into the hands of these large behemoths?

Bret 17:59
I am not sure those are different questions. My sense is, if you look at, for example, television, when I was growing up, you're not that much younger than me or that much of your 40 years. Yeah. I'm 50 ish. ish. Yeah. In any case, when I was growing up, everybody understood television to be dangerous and destructive, especially to kids. And about the time I was in high school, I started saying, it's not the box. It's the business model. The the box itself. And then you know, the thing that caused me to think that was that I spent plenty of time watching documentaries on public TV. And I didn't have the sense that I was degraded by them. In fact, I felt enhanced, I was educated by them. And so obviously, it came over the same box. And what was different was that the business model is different. Now, I don't think NPR or PBS are a model of anything at the moment, I think they've been captured by something quite dangerous. But what I do know is that HBO at first and then later on Netflix, and others have taken the very same box that was delivering really toxic content, and has repaired it by getting people to pay up front for a service and then delivering them a higher quality good that does not require the content to manipulate, you end up keeping in your seat. Okay, right. So the need to keep you coming back commercial break after commercial break caused bad content, the HBO version, where what they do is they sell you the right to watch some long form narrative and they don't interrupt it with commercials. Actually, you can do something very sophisticated in that space. And yeah, there's a lot of garbage out there still, but the point is, nothing had to change about the tech in order to change the narrative. and enhance it. And I think the same thing is going on with the net, where what we have are platforms that because of the competition they are caught in, are forced to manipulate us into sticking around longer than is healthy for us to staying on sight, as they say, when our mental health would suggest that we should get up and turn off the computer, do something else. So the real question is, if we were to fix the net, and fix the platforms that ride on it, what would that do to discourse and my guess and it's not a wild guess it's an educated guess my guess is the quality of discourse would go way up. And in fact, I think I think I dw has been a demonstration of this. So

Benjamin Boyce 20:54
what would cause the quality to go up the the need to no longer keep people stuck around, but give them something that they want, rather than something that they are told they want or manipulated into wanting?

Bret 21:05
Yes. If you fix the incentive structure around the content, and the interaction between, let's say, creators, and platforms, then that which was delivered, the quality of it would go up. And people would seek out that which served them better? You know, in a video that you filled up me quite some time ago, we talked a little bit about wisdom. Yeah. And I argued that the the core of wisdom was delayed gratification. And it's funny, in the aftermath of releasing that video, people have pointed me to lots of other places where other people have argued that that's actually the core of wisdom. So I it's a resonant idea. And I think the point is given good tools, wisdom about how to spend your time online will go up. We don't have that happening now. Because we have antagonists, we have very sophisticated antagonists who are deploying very sophisticated machine learning to keep us from getting wise to keep us coming back from for the the junk food that they're delivering.

Benjamin Boyce 22:09
Well, at the same time, I think we can be a little bit generous with at least the tension, the intentionality of the Google whatever it's called, in fairness, enhanced meant team or whatever they have. The language itself is really telling like how they frame all their little ministries is just it alarm bells,

Bret 22:28
especially the the Nothing to see here, move along ministry, what the hell is that.

Benjamin Boyce 22:35
But it seems like in the Project Veritas video, the woman that was caught on camera has higher up on some level of the appropriations or the appropriateness committee. She wants to change the election, she doesn't want Trump to happen like they are, they're really scared of Trump, they really want the world to be a better place. So it seems like they are acting out of an idea of wisdom or care concern.

Bret 23:01
Well, okay,

Benjamin Boyce 23:02
is there any way to reach them and get them to not go down this direction?

Bret 23:06
No, no, I'm utterly convinced there is no way to reach them. These are. These are maniacs who do not realize that that's what they've become. And you know, we saw this at evergreen. Yeah, was there any way to reach evergreens faster, still no way to reach which tells you something. I think that's a model of what's going on. And Google is incapable of questioning the wisdom of doing what it's doing. Now, with respect to their point about Trump, I to think that the election of Trump is a very frightening fact, as we are staring down the barrel of potential war with Iran, having a guy like Donald Trump, in charge of whether or not we go that direction, makes us much more vulnerable, I believe. And so there is something to be said for the question of what what does this mean? On the other hand, the idea that Google thinks it has the right to adjust content, so that he doesn't get elected, again, is the height of hubris. And it carries with it a very obvious danger which Google which has studied, artificial intelligence should well understand, which is, if you start with the conclusion, which is I'd like to live in a world in which Donald Trump doesn't get elected, and then you start adjusting content so that it points away from a guy like Trump, you do range us you make it impossible for us to have a nuanced conversation you have make it impossible for us to have a conversation in which the counter intuitive plays an important role. Because the algorithm, you know, it's not artificial genius. It doesn't even deserve it. Right. It's intelligence is a stretch in and of itself. So the point is, Look, you have to let us have discussions. And the fact that you and Tim Poole are finding themselves on the wrong end of this algorithm tells you everything you need to know.

Benjamin Boyce 25:12
Well, what does it tell me? I just it, I just can't get my head around why they would think I am important enough to scrub out.

Bret 25:20
Let me let me put it to you this way. It tells you that the algorithm thinks that you are bad for the future, when in fact, I've listened to you. You are a difficult, but positive force, you're a difficult force because you're forcing people to look at something they don't want to see. And you know, it's the same thing I encountered. The problem with the Evergreen story was that good people don't like a story with black bigots, black bigots were the problem. I don't like a story with black vegans. On the other hand, if there are black bigots which we encountered at evergreen, you can't decide that story is unrepeatable because it goes against the narrative that you favor, you have to say, well, what's happened? Why Why is that a phenomenon that's occurring in the present. And so anyway, my point would be, you and Tim Poole are delivering very high quality material. And for the algorithm having to decided to have decided that what you are doing is actually counterproductive tells you that the algorithm is not interested in truth. It's not interested in in depth explorations, because what both of you are doing is you're exploring things in depth so that people can see the horror show, they can also see what's being lost. And in any case, I'm against any algorithm that would decide that you and or Tim Poole were on the wrong side of history, because I believe you are on the right side of history and not an as great company. Well, I'm

Benjamin Boyce 26:53
not on the side of those who would rewrite history. We know that at this point.

Bret 26:59
You Well, you have a, an inability to look away.

Benjamin Boyce 27:04
Yeah. It seems like in that what you brought up with wisdom that delayed gratification, there's also it just makes me wonder what is that desire for us to declare an outcome or to be outcome oriented, and it seems like an unintuitive principle to not become outcome oriented, in certain respects with regards to they want Trump elected, they want to fix it with evergreen, they want to fix the numbers, even though the numbers were fixing themselves. They wanted to fix these gaps between different races and their achievements. And that equality of outcome. It seems really good. It seems like a fool's gold, though, it seems like a foolish wisdom. Do you see that? It seems like you brought that up with Google deciding where to go and then trying to muddy the waters to get there. Well, there

Bret 27:54
is a way in which something has switched sides. And the desire to stamp out inquiry at evergreen or in the academy is obviously paradoxical. And the desire to mean this is Google. Google became Google, because it allowed people to discover what was actually available in the world. It allowed it indexed it enough that we could actually find what we were looking for. And so in some sense, Google became a kind of next level perceptual apparatus like an OPI to look into civilization and what's taking place. And now what is that AI doing? It's editing, what you can see serving a

Benjamin Boyce 28:47
particular brain.

Bret 28:49
It is it is becoming paternalistic, and it has decided that it doesn't want you to look at your content, for example, and evaluate it for yourself. It's going to evaluate it for you and just, you know, disappear it and if you really want to find it, you can but you and I both know that the degree to which Google intervenes between you and your audience that adjusts your fate going forward. They've decided that they've looked at your content so other people don't have to and what the heck, Google is going to decide that. Yeah, that's like the academy deciding that inquiry is a form of oppression.

Benjamin Boyce 29:29
Yeah, it just, it's, it's all I did. I tried to design as I developed as a content creator. I'm still very early in this experiment, but I tried to design content that was complex that that kind of used that knee jerk reaction to get people into the door getting attention is important. The way that I kept attention and tried to go forward and manipulate attention or to to break apart attention and to engage in tension over the course was to be is to not feed on those clickbait things is to actually upset expectations and have long form conversations with people that you wouldn't normally have a conversation with. And it seems like if the algorithm is somehow Miss reading me in my intentions or reading a certain intention into it that they that it either can't process, that level of complexity or that level of complexity goes against what did its handlers want to happen when I think that that level of complexity, so as we're exercising right now, I don't think any machine could actually gauge what we're actually doing here. That level of complexity, I believe, is the way forward is the way for us to get to a place where we can disagree and build something while disagreeing on things or whatever we do. Well,

Bret 30:48
I I've said elsewhere, that we missed the boat with respect to the fears about AI, that we were expecting robots, and that we are actually now living the very early stages of the AI apocalypse. And we don't even know it because the robots aren't important factor that what it is, is the algorithms and in some sense, the algorithms have started to think for us. Now, here's a very basic question. Do the executives at Google have an escape from their own algorithmic adjustment of reality? Or is this a positive feedback where the executives of Google are going to be convinced by the algorithms that they stupidly set in motion? Are they going to be reinforced in there wrong? Think I hate to use that term? Yeah, ironically, here we're the ones who are so they think we're involved in wrong thing. But to the extent that they have deployed an overly simplistic view of what's worth hearing, and what isn't? Are they creating their own echo chamber, which is then going to derange them? Right. In other words, the overlords have created the seeds of their undoing. And it's, you know, it's very much like the scene in whatever movie where the robots turn on their creators. The algorithms are inevitably going to confuse people at Google, who are programming the algorithms.

Benjamin Boyce 32:20
Yeah, it seems like we every once in a while a new video surfaces from one of those dynamic companies out in Boston, where they have a robot Boston Dynamics, they beat up the robot now and the robot can sustain a beating. It's still if you look at those robots, they're they're scary. They're funny, but they're not really articulate what they what Google has done is released robots into our cultural space, which they're non physical robots, but now they're going through our cultural landscape. Are they any more adroit? Are they any less clumsy than the ones that we see in those videos?

Bret 32:54
Yeah, they're not quite adroit. They're Android. Oh, sorry, Scott. And I we can edit that out.

Benjamin Boyce 33:02
is headed somewhere, though. But it does remind me so every once in a while, I put out an evergreen video. And there's always somebody saying get over this kid, you got fired. From there. I'm like I was a student. But you know, people don't understand. But I really do think that the Evergreen the situation maps on to other things, and what you just said about Google, kind of circling the wagons or getting the robots to cut them off from discourse. They don't have any accountability to the outside world. And when we don't have accountability, just like what happened with the Evergreen story recently, the certain faculty were trying to get the faculty to have an open and honest discussion and every layer of authority above the faculty, which we're all supposed to serve, the faculty shut down that discussion, they finally had a little bit of discussion. And even within that discussion, they didn't want anybody else to hear them speaking. They, they they've, when we, when we cut ourselves off from that discourse that damages us more than anybody else, we are unable to actually look at the world because that which, which we've designed to protect us from the world ends us ends up creating huge blind spots for us going forward. Yeah,

Bret 34:08
I mean, in fact, the point is, this authoritarian stuff ends in a dystopia every time you deploy it. And we are now seeing every stripe of authoritarian, right, we saw it at evergreen, I mean, evergreen now functions like a little dictatorship. And the fact is, the faculty don't even have the ability to email each other. Right? The dictatorship decided that because faculty emailing each other was the root of their unhappiness. They cut that off, you can't reach the Board of Trustees without going through the President's right hand, man, you can't reach your colleagues. It's a little it's a little totalitarian state. Google is behaving like a little totalitarian state except it happens to be one that is now in some a morphus way. sitting right in The center of our ability to collectively think Yeah, right. That's a very dangerous process, and it's not going to end well. So the question is, you know, a, what should we think, you know, this video is going to be released on YouTube? Yeah. Will the iTunes algorithm be able to figure out will it detect that we are actually attempting to figure out how to defend liberal values? What does Google's algorithm think of traditionally liberal values? Sounds to me from what Project Veritas what, frankly, makes me very nervous, but Project Veritas, what they captured on their camera suggests that Google has moved beyond caringly liberal values, and it thinks it knows better and doesn't need them anymore. And, you know, we all know where that's headed.

Benjamin Boyce 35:52
Is there anything that we can do then other than soundly alarm? I don't want to I'm tired myself of sounding the alarm of feeding and outrage, I'd rather keep on trying to produce deep good content, but it seems like we do need to come together on some level and organize or get ready for moving in another direction?

Bret 36:15
Well give you two answers. One is, we need to read tool, the internet, which will allow us to walk away from those who have decided to think on our behalf. That's one level, and that's going to require some careful technological thinking. The other level, though, involves us figuring out how to reject the diagnosis of us. And this is a place where I think it w at least for a while succeeded. When I dw first began to form before there was even a name for whatever that phenomenon is. It was immediately dismissed by a wide range of people as a conservative phenomenon. And many people, including me kept pointing out that doesn't make any sense, at least half the people who are associated with that conversation are actually left of center. Not only that, but everybody involved in the conversation is heterodox in one way or another, and broadly tolerant. So it isn't an ideological conversation. Now, my point, though, is, at first, there was a lot of resonance to the dismissal on the basis that it was conservative, but figuring out how to respond to it without becoming enraged, and saying, no, that simply doesn't fit the fact Yeah, actually caused an update to people's model of what they were seeing. So I guess what I'm saying is, we have evidence of places where stigma that is supposed to shut down, one's access to an audience was actually repelled because the audience is interested. And there is enough openness to an analysis of what's worth listening to that, in fact, we want at least for a while,

Benjamin Boyce 38:11
that threat of stigma, stigma will always be popping up, it seems like no matter where any particular people congregate, they will be slandered. And the weird thing is, is that the people, there are these useful idiots there are these, these these little gaggles of groups that just want to go around and stigmatize people and those are being used, that that that action itself is so easily feeds into larger authoritarian movements? Because it seems like it shuts down people's ability to really engage with things and I wonder, maybe we don't have time to talk about it right now. But um, about the mechanics of stigma, and how do we see it in ourselves and, and shut it down or use it in the proper way? Well, the

Bret 38:58
most important thing is that, you know, we, I've said in many of these places where I've been asked to talk about the free speech crisis, I don't think this is a free speech crisis. Part of the problem with the framing of what we're facing as a free speech crisis, is that it focuses too much on the speaker, when in fact, what we saw at evergreen on other college campuses, is an attempt to prevent people from being able to listen to what they want to hear, right? You shut down a speaker, it's not their rights that are the most important. The question is, what about all the people who wanted to hear what they had to say, who don't now have the ability to access it? So the point of the stigma is to interrupt your ability to seek content that you want to engage with. And in some sense, that means that the solution to the stigma problem is not to deal with the stigmatizing itself, but to make sure that it does not interrupt the ability of an audience to find the content that it wants to Engage with an AI You know, there is a frightening aspect of that I don't want people engaging white nationalist content. But the reason that the founders protected speech, the way they did is that they trusted that the net effect of protecting all speech is to allow heterodox ideas to flourish when they are right. And for that, we have to accept a certain amount of speech that on the whole, we would rather not exist

Benjamin Boyce 40:33
is, in your estimation, is their forms of speech that are so toxic that they can destroy or corrupt everybody's mind, that should be like some sort of science fiction novel like the book that will upload us all into the net? Or some something very deadly or dangerous? Is there a combination of words that can ruin all of civilization that more words cancel,

Bret 40:54
you have to? You have to accept a qualified answer on that point? I don't think there's a simple answer. So I'm going to qualify, the there is no set of words that does that. But given a particular context, there is a set of words that will set us in motion in a particular direction, that is very dangerous. And the point I've been making is that economic contraction, the experience of the opposite of growth, puts people in mind of who to go after in order to restore growth for their family, for their for their kin group. And so my point is, we are actually wired for messages that will cause us to turn on people who are vulnerable. This is what happened in Germany, in the 30s. And it can happen any time. So to the extent that what we have are people, like I would argue Donald Trump played on this, I don't think it's necessarily what he is interested in. But to the extent that people's cognitive structures, we're looking for evidence of somebody who was going to point out which group we can turn on, while he's played on anti immigrant sentiment, and, you know, distrust between populations, and things like that, it's part of how he got elected. And so we have to be aware that we live in a period in which messages that we do not want to spread are likely to be more resonant than we would like them to be. It doesn't mean that those same messages would have any resonance whatsoever. Were we living in a boom,

Benjamin Boyce 42:36
okay. All right. So the answer is usually not just the words themselves, but the context in which those words might ignite a large fire.

Bret 42:45
Yeah, and maybe the simple way to say it is, there are no words that will do it. But there are combinations of contexts and words that will,

Benjamin Boyce 42:54
if Google goes through and starts to banish us from certain nutrients, let's say and then thinking that these things are bad, but just goes overboard, then it could lead us to a place where on a psychological or cultural level, we're getting hungry or needing for some sort of upheaval, that could otherwise be avoided.

Bret 43:17
I think that's true. But maybe at a more basic level, the thing that we should, the thing that we need most is our ability to think collectively, clearly, and that requires that nobody decide which fraction of the information we are able to see, as bad as it is that there is there are messages out there, that people may spread that are dangerous, it is far worse that somebody decide that they know which messages we get to see and which ones we don't. So that right is a very important one. It is not synonymous with free speech. It's related. But it is not the same thing. And we're going to have to figure out how to protect our ability to think collectively. Because it's quite clear that people wielding algorithms have set us on a very dangerous course.

Benjamin Boyce 44:06
And by thinking collectively it's the opposite of groupthink in a way it's it's together alone or together against or it's another way of framing interpersonal communication that doesn't come down to everybody thinking in a rigid form but but interacting with the opposite of rigidity sometimes Yes, the humor and and the ugly and the unnecessary, the uncomfortable.

Bret 44:33
Let me put it this way. There is no reason that language would have evolved to just synchronize people's thinking synchronizing people's thinking is not a very interesting phenomenon and it doesn't would not have caused the evolution of something as absolutely miraculous as human language. So yes, it is true that sometimes people use language to cause groupthink But the most interesting thing that language does is it allows minds that are different to compare notes and to upgrade each other. And that's what I mean by our ability to think collectively, I'm imagining something much more like a, an analog of a brain that exists in between us, that actually does result in us getting smarter over time. And to the extent that Google believes that it knows what that brain should think about stuff, we ought to be quite frightened of Google.

Benjamin Boyce 45:31
Yeah, again, they've put like an Android thing into our head and an insert of some sort, some sort of bargain modifier or enhancer that does the opposite of enhance the world.

Bret 45:43
I have to say, when I walked down the street now and I see apples, your buds hanging out of people's ears, I do sort of have a sense. I'm not sure why it strikes me as more dire than when they had, you know, your phones with cords. But there is something about a large fraction of the population walking around with a particular conspicuous electronic augmentation hanging out of both ears. That makes me think, Oh goodness, where have we ended up? All right, Benjamin. This has been marvelous what I'm hoping we don't live that far apart. What I'm hoping is that you'll come down and we can have further conversations about what's taking place and what it means because it's always a pleasure engaging with you.

Benjamin Boyce 46:30
It's been absolutely wonderful. Thanks for terrific, thanks, Benjamin.

Bret 46:33
All right, for the rest of you, I would say if you want more content like this hit like and subscribe and maybe hit the notification button and we will talk more about civilization as it develops.

Benjamin Boyce 46:46
Oh, and find my channel in the description somewhere.

Bret 46:49
Also, his channel will be linked in the description that was very impolite of me not to mention that but of course it would have been in it will be and so you can find him there if you're not already subscribed, which is what I suspect. Okay, signing off.

This transcript was generated by https://otter.ai