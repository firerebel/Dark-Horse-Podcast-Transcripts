Bret 0:03
Hey folks, welcome to the Dark Horse podcast, I am very pleased today to be sitting with my good friend Daniel shmotkin Berger, who is the founder of the consilience project, there's a lot more that I could say about you, Daniel, but I think we will leave it at that for now people can look up your bio, if they want to do so, I should probably start by telling people that when I say that you are my good friend, I really mean that you and I are good friends. Although to be honest, we haven't spent all that much time together. This is one of those cases where you meet somebody, somebody who has started from a very different place, and you discover that you have all kinds of thought processes that have reached similar conclusions. And every discussion is fascinating. The more I learn about what you think, the more I realize, I've got a lot to learn from you, and that there is essentially infinite ground to be covered. So welcome, Daniel.

Daniel Schmachtenberger 0:57
Thank you, Brett. It's really good to be here. I feel the same way. And we were introduced by our friend Jordan Hall. And we've never had a conversation where I didn't learn something and where I didn't appreciate the good faith way that you showed up when we had a disagreement to talk through, which is always fun. It is

Bret 1:17
always fun. And I must say I did a little bit of poking around seeing recent interviews you done. But I deliberately did not overly study for this. My sense is that the audience will get a great deal out of hearing you and me go back and forth and finding out what we agree on where we disagree. And maybe most tellingly, there's a phenomenon in which anybody who has learned to think more or less independently tends to have their own language for things, their own set of examples that they use to explain things that recur over and over again. And so in order to have high quality conversations, there's this this period in which you're effectively teaching the other person, how you phrase things, and seeing those things line up is great. And in the rare case where they don't line up, it's even better because you know, there's something to be learned one way or the other. So I'm hoping that will emerge here. I'm looking forward to it. All right, good. So let's start here, when I say that you and I come from different starting points, I mean, to imply something, in particular, you, as I understand it, were homeschooled, and as you have described it, that was actually closer to what most people would probably refer to as unschooling, somehow this did not mess up your motivational structures, your parents were alert about what they were doing. And so you ended up pursuing what you wanted to pursue. And it did not, you did not get in your own way. And lo and behold, you end up a wickedly smart, independent first principles, thinker. Now, that's not my story at all. My story is I went to school, and it didn't work. I had something that most people would call a learning disability, and it got in the way of school functioning for me. And more often than not, I got dumped tracked. And basically, that complete failure of school to reach me accidentally worked like some kind of unschooling, I would say, and so there are maybe many paths, I don't know. But I'd be curious, for people who have traveled some road to the land of high quality independent thought, What can they expect the experience to be like when they arrived there?

Daniel Schmachtenberger 3:50
The experience of high quality independent thought,

Bret 3:54
yes, if you imagine that, well, it would be lovely to think independently, and to do so well. And the world is going to be a paradise if you start doing that, because of course, that's a very desirable thing to do, and people will appreciate it, you're going to be surprised. That's not necessarily what happens when you arrive there. And certain experiences show up all over the place. And without telling you what my experiences might have been. I'm curious as to what you might have encountered and whether or not those things will be similar.

Daniel Schmachtenberger 4:24
Yeah, it's interesting question. I think you will experience most people will experience a higher degree of uncertainty than people that are part of any camp that has figured most things out and they can cognitively offload to whoever the authorities or the general group consensuses. And certainty is certainly comfortable in a particular way. And if you're really thinking well about what is my business For what I believe, what is the epistemic grounding? What's the basis of my confidence margin, and you really think about your confidence basis clearly, as you try to find more information to deepen the topic, the known unknowns expand faster, like at least at a second order to what the known knowns do. And so you keep being aware of more stuff that you don't know that you know, is relevant and pertains to the situation. So there's a complexification of thought, there's an increase in uncertainty, hopefully, there's an emotional development, and kind of a psychological development where there's an increased comfort with uncertainty so that you can actually be honest and not defect on your own sense making into premature certainty that creates confirmation bias. And there's also a and I think that's why one of the reasons you use the term independent. There is a certain aloneness of not having a whole camp of people that think very similarly. I don't find that to be painful thing. But it's a thing.

Bret 6:12
No, it's actually in its own way. It's freeing, because the fact is, if you follow logic to natural conclusions, you'll end up saying a lot of things that are alarming or discordant with the conventional wisdom. And the world neatly divides into people who will be so enraged or thrown by what you're saying that they disappear. Or maybe they become antagonists at a distance. And the people who have a similar experience and therefore aren't thrown by the fact that you're saying things that are out of phase. And so editing the world down to those who are comfortable with what they don't know, who are interested in following things where they lead, irrespective of who that elevates and who it hobbles, those people are interesting people to hang out with. And so yes, the, the alienation may be a blessing in disguise since in some ways,

Daniel Schmachtenberger 7:20
listen to other thoughts that came up as you're just talking. One is I, I wouldn't call myself an independent thinker. I'm being particular about the semantic of the word independent, I wouldn't call anyone an independent thinker, because I think in words invented by other people, I think in concepts invented and discovered by other people. I don't necessarily have a specific school of Orthodoxy from which I take an entire worldview. But almost every idea that I believe in I did not discover. And so I think that's a very important concept, because I think the the ideas we're going to discuss today regarding democracy and open society have to do with the relationship between an individual and a collective. And I think the AI there, the idea of an individual is fundamentally a misnomer without everybody else, I wouldn't be who I am. And I wouldn't think that way, I think, who wouldn't think in the language I do, I wouldn't have access to, you know, the knowledge that came from the Hubble telescope and the Large Hadron Collider, and so many things like that. So I can say that there's a certain like, ultimate authority, that of what I choose to feel that I believe in and trust that has an internal locus of control. But the information coming from without and my own internal processing of it are part of the same system.

Bret 8:51
So this is a perfect example of what I was suggesting up front where two people who do whatever we're going to call this will, will have their own separate glossaries. So if I can translate what you've just said, I, Daniel Martin Berger, am not an independent thinker because such a thing is inconceivable in human form. Right? And I totally agree with that. The fact is, not only are you interwoven with all sorts of humans who are responsible for conveying to you in one way or another conclusions that you couldn't possibly track you know, these are thoughts that would be familiar to decart for example. But you are also building from the entirety of cumulative human culture, right, all of the tools with which you can think are almost all of them are too ancient to even know where their rudiments originated. So anyway, I don't disagree with any of that. So to me, I would say there is such a thing as an independent thinker. And in your schema, it has to do with whether or not they are thinking all a cart. That is to say Using that set of tools that is most effective irrespective of the fact that those tools don't all come from one tradition. And you would say there is no independent thought because all a cart is the most you can do or something like that.

Daniel Schmachtenberger 10:15
I might say that I like a term like interdependent better, because it doesn't mean that there isn't an individual involved. But it means that the individual without everyone else is also not a thing. And so, the recognition that sovereignty and individuality is a thing. And it is conditioned by affected by an affecting other groups of people are both necessary in The Hague alien synthesis to understand what is the nature of a human, are they fundamentally individual, and then groups emerge? Are they fundamentally tribal, and they're formed by the tribe, and it's very much both in a kind of, recursive process between them

Bret 10:54
100%. In fact, I once wrote something I called the declaration of interdependence, it was a sort of proto game be attempt to define what the rules of a functional society would be like. And I also frequently say that the individual is more an illusion than it is real. And what I describe is that an individual is a level of understanding that evolution has focused us on because historically, it has been sort of the limit of that where we might have some useful control. Right? evolution might ultimately care about whether or not you are successful, your genes are still around 100 generations from now. But your focus on 100 generations from now is unlikely to have any useful impact whatsoever, whereas your focus on your life and your children is likely to be useful. So we have we have been delivered a kind of temporal myopia in order to keep us focused on that which could be productive for an ancestor. But of course, we are now living in an era in which we can have dramatic impacts on the distant future. In fact, you and I are both quite focused on the strong possibility that our foolishness in the present will result in the end of our lineage. And that that is something that evolution where it capable of upgrading would certainly have us concerned about because the hazard is very real. And our tendency not to think about it is a big part of the danger.

Daniel Schmachtenberger 12:41
I think, temporal myopia and the collective action collective coordination problem is a good way to describe all of the problems we face or one of the generator functions of all the problems we face that you have a bunch of game theoretic situations where each agent within their own agency pursuing the choice that makes most rational sense to them pursues local optimum, where the collective body of that drives local minima, global minimums, but if anyone tries to orient towards the longer term global maximum, they just lose in the short term. That's an arms race. That's a tragedy of the commons. And so how do we reorient the game theory outside of those multipolar traps, I would say is one of our underlying questions, that when the biggest harm we could cause was mediated by stone tools, or bronze tools, or iron tools, or even industrial tools, we didn't have to cause it immediately because the extent of harm was limited in scope. When it is mediated by fully globalized exponential tech running up against planetary boundaries with many different kinds of catastrophe weapons held by many different agents, we actually have to solve the problem.

Bret 13:51
I of course, agree completely with this as well, that effectively, maybe it really is, every single important problem is a collective action problem of one kind or another. We've got races to the bottom, we've got tragedy of the commons, we've got these things, intermingled. But once you start to see that, on the one hand, it is you could take from it a kind of reason for despair, because these are not easy problems to solve. On the other hand, the discovery that effectively, it's not 1000 distinct problems, it's 1000 variations on one theme, and that that theme is solvable. In fact, we have for example, l&r awesomes work, which points to the fact that evolution itself has solved these problems many times. That that is hopeful so I don't know where you are in terms of how hopeful you find yourself about humanity's future. But I'm quite certain that you and I will align on the idea that, yes, if we could focus on the problem as it was, it's more tractable than many people think it is.

Daniel Schmachtenberger 15:09
Yeah, I mean, you mentioned hopefulness. You mentioned a bunch of good things there, that rather than a bunch of separate problems, you have a few problems with lots of expressions. This was a big chunk of the kind of work I engaged in with a number of people, you were part of looking at. When we inventory across all of the catastrophic and existential risks, ones involving AI and problems with biotech and other kind of exponential tech and environmental mediated issues and things that escalate to large scale war, is there anything in terms of the patterns of human behavior that they have in common, and so this kind of race to the bottom collective coordination thing is one way of looking at that. But there's a there's a few ways of looking at what we'd call the generator functions for catastrophic risk. And it really is simplifying if you can say, Are there categorical solutions to those underlying generator functions? They're hard, right? They're, they're hard. Now when you talk about hopefulness, I noticed that the way that I relate to the optimism pessimism thing is there's an optimism, which is almost like a choice. To say, I'm going to have optimism that's that there is a solution space worth investigating, even if I don't know what it is. And if I'm wrong, that's it's the right side to be wrong on as opposed to there was a solution, I didn't look for it. And then I'm going to have pessimism about my own solution. So I'm going to try to read to you my solution so that I can find out how they're going to fail before finding out how they fail the hard way in the world, but then not be devastated by the fact. And that might that solution, wasn't it and keep trying. And I think that's kind of how the committed Lee inventive, innovative principle works.

Bret 17:01
So yeah, again, we've we could do almost a one to one mapping of your schema onto mine, I do this in terms of prototyping, rather than red teaming and discovering it's wrong, it amounts to the same thing. When you say, actually, it's hard you and I would have to define two different kinds of hard probably, there is hard to make function to stabilize. And there's hard to figure out what the solution is. And those are distinct, we might find elements of both of them here. But let me just give a maybe it's the canonical example of of a solution to a game theory problem that everyone will recognize. I divide you choose, right? It's the perfect solution to an obvious problem of choice and selfishness, right? If there is cake, and I know that you're going to get your choice, and that you are incentivized to pick the larger piece than I am incentivized to get the cut as even as possible. And the point is, it neutralizes the concern. So we are looking for solutions of that nature. Now, I don't think they are all that hard to understand in broad terms in generally made, there may be a lot of work on the Discovery end, but when you see them, they end up being surprisingly simple. My biggest fear is that the there is it is very rare for people to understand how much danger we're in, and why. And therefore what solution we are inherently looking for, and how urgently we should be seeking it. In other words, as long as things function pretty well, in the present, and people get fed and housed, it is very easy for them to ignore the evidence that we are in grave danger, even if we are fat and happy and enjoying a, you know, a period of good luck.

Daniel Schmachtenberger 19:14
Yeah, when you like one of the interesting things in the study of previous civilizations is that none of the great civilizations of the past still exist. They all failed, even if they had been around for hundreds or 1000s of years. And so to understand that civilizations failing, is the only thing that's ever happened and then recognize that since World War Two, we have for the first time a fully globalized civilization where none of the countries can make their own stuff that the supply chains that are necessary to make the industrial and productive base are globalized. And that we're running up against the failure points of a globalized civilization which it that's an important thing. And what's so interesting is that all the previous civilizations that failed, had so much hubris before their Because there had been so many generations where they had succeeded that they had forgotten that failing was a thing, it was just some ancient myth, it didn't feel real. So we don't have an intuition for things not working or for catastrophe, because we haven't experienced it. And our parents didn't experience it. And it's only myth. And as a result, we just make bad choices. And I mean, this is where studying history and studying civilizational collapse is really helpful. And you can see that even as the system starts to fail in partial ways, that you know, to me, it seems very clear that when we look at the George Floyd protest, turning into riots over the summer that happened, they were following the COVID shutdowns and specifically all the unemployment from it, when and whenever the unemployment goes up, whenever the homelessness goes up, when people can't, when the society makes it to where people who are trying can't meet their basic needs, then it gets a lot easier to recognize there's something wrong with the system as a whole and go against it. But we also never had a point in human history where it was like, no matter how outraged I am, all I have to do is start scrolling for a second and I forgotten everything, not to mention the fact that I'm probably on opioids and benzos. And so that, that makes it to where the frog can keep boiling in hot water longer.

Bret 21:21
Yeah, so I I often say that people are too comforted by the idea that people are always predicting the end of the world. And it hasn't happened yet, because in fact, it happens all the time, right, the ends of these civilizations. But it's even worse than the analysis that you and I appeared appear to agree on here, because many of those civilizations that have ended, in fact, most of them, the civilization, the organizational structure ended, but the people didn't write. So the Romans continued on as other things, the Maya are still with us, right? They are not with us as the Maya. And the point is actually, in this case, the Jeopardy that we are creating is to our very capacity to continue as a species, not just to our ability to continue with the structures that we have built. So not only are we all in it together this time, but we're all in it in a way that we never have been before, or at least very rarely have been before. And that really ought to have people's attention. But you're right, the capacity to distract ourselves from it has never been better either.

Daniel Schmachtenberger 22:31
I think something that I find particularly important when thinking about catastrophic risks now, relative to previous examples of civilization collapse, is that until World War Two, we couldn't destroy everything. Like we just didn't have enough technological power for catastrophe weapons. And so you could fight the biggest bloodiest war violate all of the rules of war, and they would still be a local phenomena. And with the invention of the bomb, we had now the new technological power to actually destroy habitability of the planet kind of writ large, or at least enough of it, that it was a major catastrophic risk. And on the timescales that you think about as an evolutionary biologist of how long humans have been here and the, you know, protohumans. since World War Two is no time at all have really adapted to understanding what the significance of that is. And the only reason we made it through was because we created an entire global order to make sure we never used that new piece of tech and then all of history we always use the armies that we developed. And so we made this whole Bretton Woods world and mutually assured destruction that said, Okay, well let's have so much economic growth so rapidly that nobody has to fight each other, and they can all have more because the pie keeps getting bigger. But that starts running up against planetary boundaries and interconnecting the world so much it gets so fragile that you know, a virus in Wuhan shuts the whole world down because of supply chain, you know, interconnected supply chain issues. So that thing can't run forever. And the mutually assured destruction was one catastrophe weapon and two superpowers. So mutually assured destruction works, the game theory that works. Well, as soon as you start to add to that the bio weapons and the chemical weapons that the the fact that bio weapons can be made very, very cheaply. Now with CRISPR gene drives and things like that drone weapons, we have dozens of catastrophe weapons held by many dozens of actors, including non state actors. And that just keeps getting easier, mutually assured destruction can't be put on that situation. It doesn't actually have a stable equilibria. So now we have to say how do we deal with many, many actors having many types of catastrophe weapons that can't have a forced game theoretic solution? with a history where we always used our power destructively at a certain point, how do we deal with that it's novel, right? Like we have no precedent for that.

Bret 24:56
Yeah, it's absolutely novel. I mean, when I became Cognizant, you know, let's say 1975 is where I first started having, you know, coherent thoughts about the world that was only 25 years after the end of World War Two. And it seemed like World War Two was a very long time ago. But of course, we've covered that distance twice since then. So the ability for you know that the tools with which for us to self destruct as a result of aggression, are brand new. And you're absolutely right, the thing that caused us from using them, or prevented us from using them, that force disappeared, it no longer exists, there's no stable, stable equilibrium here. So what's protecting us is not well understood at best. And then add to that all of the various industrial technologies that we are now using at a scale where they imperil us. And I don't know about you, but I keep having the experience of a catastrophe happens. And that's the point that I get alerted to some process that is very dangerous to humanity that I didn't know about until the catastrophe. Right. This has happened with the financial collapse of 2008. It happened with the triple meltdown at Fukushima, it happened at Aliso Canyon, I believe it has now happened with COVID-19, and gain of function research. And the point is, it paints a very clear picture, we do things because we can't see why we shouldn't or this is also a game theory problem. Those who can see why we shouldn't don't, and certain number of people don't see why we shouldn't. And they do. And we all suffer the consequences of their myopia. And so on multiple fronts, we are playing, you know, we are rolling the dice year after year. And the people who can think independently looking at that picture, looking at the series of accidents, looking at the hazard of something like a large scale nuclear exchange without an equilibrium to prevent it, those people wake up. But the problem is the mechanism to actually begin to steer the ship in a reasonable direction in light of these things, doesn't seem to exist. For reasons I've heard you explore many places. So what does it mean, as far as you can tell?

Daniel Schmachtenberger 27:25
There's one thing that you said that I think is worth us addressing first is that some of the things that caused the catastrophe either were unknown, or those who knew them or game theoretically less advantaged than those who were oriented on the opportunity rather than the risk because those who orient towards opportunity usually ended up amassing more resources that equals more ability to keep moving stuff through. There is a article and a conversation in the less wrong community about regarding catastrophic risk mistake theory versus conflict theory, what percentage of the of the issues come from like, known stuff that we knew would cause a problem or at least could cause a problem? And game theoretically, we went ahead with it anyways, versus stuff where we just couldn't have anticipated or really didn't anticipate. And I think it's fair to say these are both issues, right? There's there's true mistakes theory stuff, like we just couldn't calculate. And then there's true conflict theory stuff, we knew that escalating this military capacity would drive an arms race where the other people would that if we calculated it, there's an exponentiation on all arms races, that takes us to a very bad long term global situation. One of the insights that I think is really interesting is that the the fact that the mistake theory is a thing and everyone acknowledges it ends up being a cover a source of plausible deniability for what's really conflict theory. So we we know, there is an issue we pretend not to know we do a bullshit job of due diligence and risk analysis, and then afterwards say it was a failure of imagination. And we couldn't have possibly known. I have actually been asked by companies and organizations to do risk analysis for them, where they did not want me to actually show them the real risks, they wanted me to check a box. So they could say they did risk analysis so they could pursue the opportunity. And when I start to show them the real risk to like, pop, we don't want to know about that. And so when it comes to the could we have possibly factored that? So I mean, a classic example. I like to give because it's so obvious in retrospect is could we have known in the development of the internal combustion engine that making streetcars which seemed like a very useful upgrade of having the horse internalized to the carriage would end up causing climate change and the petrodollar and wars over oil and oil spills in mass and ocean oil spills, whatever. It seems like that would have been hard to know 100 years in the future that it would do all that stuff. And this is a classic case. sample is also where we solve a problem and end up causing a worst problem down the road. And the nature of how we do it, which you can't keep doing forever. The story is, oh, we cause a worse problem than that's the new market opportunity to solve that problem in the ongoing story of human innovation. But when you start running up against it, the problems are actually hitting catastrophic points. You don't get to keep doing that ongoingly you don't get to regulate after the fact, the way that we always have once a problem hits the world, things that are catastrophic. Could we have known? Well, you have in London before that, one, there were already electric motors. And two, people are already getting sick of burning coal from lung disease from the burning of the hydrocarbons. If we had tried to do good risk analysis, could we have? Yeah, but there's so much more incentive on who pursues the opportunity first. And then there's this multipolar trap of, well, let's say we don't the other guy is going to so it's going to get there anyway. So we might as well be the ones to do it first. And that thing ends up getting us all the time, which is why collective action again, comes in.

Bret 31:08
Well, it's really interesting how much of this is again, parallel? Heather and I use the example of somebody you know, driving the first internal combustion engine and somebody chasing them down the street saying, don't do that, you'll screw up the atmosphere, right? How crazy is that person running down the street saying that because, you know, you would have to scale it up to such a degree before that's even a concern that that person seems like a nervous Nellie. But of course, they would also have been prophetic. But the other thing I want to ask you about is, you say that we have these two categories, where sometimes we could have known and we went, we knew, in fact, and we went ahead anyway. And then in other cases, we didn't know and something snuck up on us. And I want to be, I want to clarify what you just said, because my understanding here is that if you dig deep enough, somebody always knew, right? In general, there's some mechanism whereby the person who correctly predicted what was going to happen has been silenced. Often, they lose their jobs, they disappear from polite society, at the point they turn out to be right, their reputations are never resurrected, as far as I can tell. So am I wrong? That even in the cases where people who made the decisions may plausibly have not known that the reason they didn't know is because there's some sort of active process that when there's a process of profit to be made, shuts down anything, that could be the basis of a logical argument that we shouldn't do it?

Daniel Schmachtenberger 32:47
I don't know that I'll say always, or I'll certainly say most of the time. And let's say there was a case where we like really, nobody knew. It's usually my guess, is, we probably could have had we tried harder. And then let's say there's going to be some unpredictable stuff. Like we know, in complex situations, there's going to be unpredictable stuff. So you do the best job you can to forecast the risks and harms ahead of time. But then you also have to be ongoingly monitoring. Well, what would the early indicators that there's a problem be and how do we take when we find that there's something we hadn't anticipated? How do we factor that into a change of design? Well, once once the profit stream is going and the change of design fucks up the profit stream? How does the recognition of that there's a problem actually get implemented when those who have the choice implementation power are not the people who are paying attention to those indices? So yes, I would say and it's easy to just say, hey, yeah, there was some there was some wackadoodle, who was saying that there was going to be some risk, but there's always some wackadoodles saying there's gonna be risk about every new tech. And if we really listened to all them, we'd have no progress. That's the story, right? It's a bullshit story. Could we now let's there's but there's a collective coordination issue. Because it is fair to say so like, let's take AI weapons right now, specifically, automated drone weapons. There is an arms race happening on automated drone weapons. And I think every general and military strategist knows that all of our chance of dying from AI weapons goes up. Their kids, everybody's as we proceed, as we progress in that technology. It's a bad technology shouldn't exist. We should create an international moratorium that says nobody builds AI, drone weapons, that we don't want automated weapons with high intelligence out there. But we can't make that moratorium because if one country doesn't agree if one non country, some not State actor doesn't agree that has the technology. Or let's say everybody agrees, how do we know they're not lying and developing it as an underground black project. So either we don't even make the agreement or we make the agreement knowing we're gonna lie defect in the black project, spy on their black project and try to lie to their spies who are spying on us? And so it's like, how do you get around that thing, where if anyone does the bad thing in the near term, it confers so much game theoretic advantage that anyone who doesn't do it loses in the long term, why it was that the peaceful cultures all got slaughtered by the warring cultures. And so what ends up making it through is those who end up being effective enough at war. That's an underlying thing, we have to shift. Because that has as its eventual attractor, space, self destruction and finite space.

Bret 35:47
Yeah, I totally agree. And the I think, fascinating thing, when you interact with the incarnate aspect of the process you just described is that the people who are telling the lies that explain why we're doing something that we know is reckless, often don't know that that's what they're doing. Right? They actually believe their own press. And instead of saying, Well, yes, this is terrible, but we don't really have a choice, or somehow indicating that they know that what you encounter is a true believer who thinks that this is safe. And that's very frightening, because it means that the mechanism at the point, something begins to go awry to do anything about it doesn't exist, right, or at least it's not connected to the part that you can talk to. And so, again, not not too surprised to find overlap in our map, I would say the process that you describe of by the time you discover what the hazard is, that there's a profit that has accelerated the process. I call this the senescence of civilization, because it's actually exactly a mirror for the process that causes a body to sin. That's the evolution of senescence involves processes that have two aspects one, which benefits you when you're young, and another, which harms you when you're old. And because many individuals don't live long enough to experience the harms in old age, they get away with it from evolutions point of view. And evolution favors the trait in spite of the late life harms. So those late life harms accumulate. And that's the reason that we grow feeble with age and die. And that's an exact mirror for the way we've set up our economic and political system. We're any process that is profitable in the short term, at the risk at the consequence of having some dire implication for civilization later on. Those processes are so ingrained by the time we discover what the harm looks like in its full form. There's nothing we can do to stop them.

Daniel Schmachtenberger 37:51
Okay, so let's use two really important current examples. So let's take Facebook and social media and the way they've affected the Information Commons and the epistemic Commons writ large. So we know that the nature of the algorithm is optimizing for time on site, well, being able to factor what I pay attention to the whole Tristan Harris story makes all it very few people wake up and say I'd like to spend six hours on Facebook. And so I'm going to spend more time on Facebook, if I kind of leave executive function, rational brain and get into some kind of limbic Lee hijacked state where I forget that I don't want to spend my whole day on Facebook. And so time on site maximization appeals to existing bias and appeals to limbic hijacks. So if I piss off and scare the whole end, and elicit sexual desire and whatever of the whole population, while doubling down on their bias, and creating stronger in group identities associated without group identities, the algorithms optimize well it is an AI of the power that beats Kasparov at chess, beating us at the nature of the control of our attention. So we can see that the right got more right the left got more left the conspiracy theories got wackier, the anti conspiracy theory people became more upset at the idea that a conspiracy could ever exist. Basically, everybody's bias doubles down and they all move apart from each other faster. Well, society doesn't get to keep working that that is a democracy killer, right? That's an open society killer. This there's a reason China controlled its internet is if you don't want your society to die, you have to be able to have some shared basis of thought. So we can say, and the story is Oh, we didn't know that was going to happen. Well, you go back and look and guys like Jaron Lanier were at the very beginning of Facebook and Google whatever saying Hey guys, this ad model is gonna fuck everything up. Like you can't do the ad model thing. You got to have paid for subscription or, you know, some other kind of thing. And it was like, shut up, dude. And Just don't even engage in the conversation and then get a say afterwards failure of imagination. But now, how do you regulate it when those corporations are more powerful than countries, because some of the regulation is going to be happening in a court where the lobbyists have to be paid for by somebody, right? So who are the lobbyists paid for by and it has to be supported by popular attention. And those who can control everybody's attention can also affect what is in popular attention. So this is a very real example where we know the harms were not. And, and it actually got large enough that it killed the regulatory apparatus capacity.

Bret 40:36
Absolutely. In fact, again, this is going to be another alignment of our maps. So what I've been playing with is the idea that we are incorrect in imagining that people necessarily want their their expectations flattered that people actually may like to be challenged, but that it's inconsistent with the well being of advertisers that the very fact is, because advertising is only a tiny fraction informative, and is mostly manipulative, you have to be in your unconscious autopilot phase, in order for it to cause you to buy a car you wouldn't have otherwise bought or buy different deodorant than you would otherwise buy. And so the point is, in order for us to be the thing gets paid for by advertising, in order to be useful to advertisers, we have to be unconscious. And the only way to keep us unconscious is not to challenge us, basically to tell us what we think we already know, rather than what we need to know. And so they're lulling us into this even though we would still be interested in the platform's if we weren't being advertised to. But we would be interested in having more important conversations there, which is really, in some sense what the growth of heterodox podcast space is about.

Daniel Schmachtenberger 41:55
Oh, my goodness, okay, there's two directions, I want to go at the same time. And I'll just pick one. There's a reward circuit on exercise. And there's a reward circuit on junk food, right. And they both have a dopaminergic element and reward circuit, but they have a very different kind. And the reward circuit on exercise is that it actually feels like shit at first, and is hard and but your baseline of happiness measured in whatever dopamine opioid axis, whatever, it gets better over time, and then you start actually feeling over time. But not quickly. This is another place where temporal myopia ends up mattering, because there's a delayed causation on the healthy one and no delayed causation on the unhealthy one. So I start getting the reward circuit on exercise when I start seeing results, and then I want to push hard and then I'm willing to actually go against entropy and put energy into the systems the energy grows, whereas the chocolate cake, I get a reward instantly, and I don't have to apply any energy. But as I do it, my baseline gets worse. And this is the like addiction versus health reward circuit direction. And the same is true for scrolling Facebook, compared to reading an educational book, at the end of a month of reading the educational books, my life feels better, I feel more proud of myself, at the end of a month of scrolling Facebook, I'm like, What the fuck am I doing with my life. And, and yet, that one will keep winning for the same reason that 70% of our population is overweight, and over a third of them are obese. And so, but not, but my only hope is that not everyone who has access to too many calories is obese, right? Like there are some people who figured out Hey, that's a reward circuit I don't want to do and I'm going to exercise and I'm going to not eat all of the fat sugar salt that evolution programming to have a dopamine hit for because it's it's a shitty direction. Now we need to get that number of people who actually have taken some sovereignty over their fitness and well being in the presence of the cheaper reward circuit, we need to get that number up to everybody. Because right now obviously overweight is one of the main causes of death in the developed world. But we have to then apply that to the even more pernicious hyper normal stimuli. Because salt, fat sugar or hyper normal stimuli on in the gustatory system, right? We have to apply that to the sensory system that's coming in through things like social media. And that means less social media, less entertainment, more study. And it doesn't have as faster reward circuit. It just doesn't. But it has a much better longer term reward circuit where your baseline goes up. And this is where enough mindfulness and enough discipline have to come in. Because otherwise, the orientation of the system is that it's more profitable for corporations for me to be addicted because you maximize lifetime value of a customer through addiction. And it's an asymmetric war because they're a billion or trillion dollar company and I'm me, so how do I win in that asymmetric war where it's in their profit incentive, whether it's McDonald's or Facebook or Fox for me to be maximally dicted I have to recognize Holy fuck, right? Like I actually have no sovereignty. Even if I claim to live in a democracy, I can do the caucuses, who want to control or manipulate my behavior in a way that is net negative for me holistically while having the plausible deniability that I'm choosing it because they're causing my choice. So I have to get afraid of that enough that I mount a rebellion, right? A revolutionary war in myself against those who want to drive my hyper normal stimulus reward circuit. So the whole How Can everybody become more immune to the shitty reward circuits and notice them and become immune to them? And how can they become more oriented to the healthy reward circuits, that's another way of talking about what we have to do writ large.

Bret 45:41
Yeah, that's beautiful. I completely agree. In fact, it dovetails with another thought that first time I thought it, I thought it was original. And then having said that, I discovered lots and lots of people had said it before me that there's a very close relationship between wisdom and delayed gratification, that it's the ability to bypass the short term reward circuit in order to get to something deeper and better. That is, you know, that is what wisdom is about. But you didn't include on your list, what I consider to be maybe the one of the most important instances of the failure that you're talking about, which is sex, there's a very direct comparison, at least for either males who are wired, in a normal fashion for a straight guy, or women who are toying with that same programming, which I believe there are many. But the comparison between casual sex, which is certainly we are at as males wired to find that a very appealing notion because it's such a bargain, if you can produce a baby, where you're not expected to contribute to its raising, that's a that's a huge evolutionary win. And then you have to compare that to the rewards of a deep, romantic, lasting relationship with commitment. And the problem is that the deep lasting relationship stuff has a hard time winning out over the instant gratification thing if the instant gratification thing is at all common. And so that's really screwing up people circuitry with respect to interpersonal relationships, and bonding. And I have a sense that it is also in a way that's much harder to demonstrate contributing to the derangement of civilization, that people, many fewer people have a relationship, you know, it's not like, marriage is easy, right? It's not it's super complex. But having somebody who you can fully trust somebody who you've effectively, you know, fused your identity with to the level that they share your interests. And, you know, they may be the only person who will tell you what you need to know, at some points. And the fact that many people are missing that I think is deeply unhealthy.

Daniel Schmachtenberger 48:15
Yeah, so I would say that market type dynamics, benefit from exploiting the shitty reward circuits across every evolved reward circuit access. And so from an evolutionary point of view, survive and mate are the things that make your genes get through primarily. So we've mentioned the survive the calorie one early, earlier, right? So in an evolutionary environment, I could get plenty of green leafy things in many environments. It was very hard to get enough fat, enough sugar and enough salt, those were evolutionarily rare things. So more dopaminergic hits on those so fast food ended up figuring out how to just combine fat, salt, sugar, with no other nutrients with maximize ease of palatability and textures. And there's like a scientific optimization of all of the dopamine hit with none of the nutrients so you can actually be obese and dying of starvation, right? And what that is to nutrition where you would should have a natural dopaminergic hit on something that has nutrients built in for you know, adaptive purposes, is what porn and online dating is to intimate relationship is what face book and Instagram is to tribal bonding is how do we take the hyper normal stimuli part of it out, separate it from the nutrients and make a maximally fast addictive hit that actually hasn't? None of what requires energetic process?

Bret 49:54
Yeah, I've called this the junk ification of everything and it is directly an illusion to junk. Where we can most easily see this, but the idea is you will be given a distilled. So if I can rephrase what you said, in terms that are more native to me, when you are wired to seek, you know, the umami tastes, that tends to be very tightly correlated with meat, you will tend to get a lot of nutrients along with it in in the ancestral context, in the modern context, we can figure out how to just trip the circuit that tells you to be rewarded. And it's no longer a proxy for the things that it was supposed to lead you to. And as you just said, you can now look at that across every domain where you have these dopamine rewards, and understand why people are, you know, living in the world that pinker correctly identifies we are living in where we have just a huge abundance, and yet are so darn unhealthy, certainly unsatisfied, right? It explains that that paradox of being better off in many ways than any ancestor could have hoped to be. And yet being effectively ill across every domain.

Daniel Schmachtenberger 51:15
Yeah, I will say something about this. It's important. I mean, briefly, the fact that life expectancy started going down in the last five years in the US in certain parts of the developed world is really important to pay attention to. But the deeper point I want to make is the hubsan view on the past, I think is one of those like mistakes, theory information theory things. I mean, mistakes theory, conflict theory, I think the dialectic of progress is such a compelling idea. And we're oriented to the opportunity and not the risk in the same way we don't want to look at the risk moving forward, that would have us avoid an opportunity. We don't want to look at good things in the past. And we don't want to look at good things of cultures that we want to obliterate. So we want to call the Native American savages so that we can of course emancipate them historically, and we want this hub Xion view that people had brutish, nasty mean short lived lives in the past show that we don't have to face the fact that advanced civilizations failed. And that is what our own future most likely portends, I think, I think that is a convenient wrong belief system in a similar way. Well, I

Bret 52:29
hope you don't hear me doing that. I

Daniel Schmachtenberger 52:32
certainly don't, I just had to say it, you have to

Bret 52:34
say it. So it's clear to our our listeners, well, I appreciate you doing that, I did want to go back to a couple things you said. And you know, of course, this happens every time you and I talk where every every thread, you know, takes on multiple possible directions, we could go and there's no way to cover them all. But in any case, you pointed to survival and mating being the primary mechanisms to get your genes into the future. And I want to point out that this is one of these places where our wiring, which is biased in the direction of those places where our ancestors had agency that was meaningful, up ends us and in fact, this is something I think you and I are struggling against. As we try to compel people of the kind of danger we're in and the necessity to upgrade our system, you know, before we run into a catastrophe, too big to come back from. And so in any case, within your population, survival, and mating makes sense as an obsession. But probably the biggest factor in whether or not your genes are around 100 generations from now is whether the population that you were a part of persists. And so, you know, my field has done a terrible job with this, we have gotten pretty good at thinking about individual level adaptation and fitness. And you know, when I say lineage, people still don't know what I'm talking about. And they're confused about why I'm focused on it. And my sense is, it's like, two components to an equation. And, you know, you're either aware of the lineage thing, but you misunderstand it as group selection, or you're not aware of the lineage thing. And you think group selection is a fiction, and it's all about individuals. And you know, both of those are ways to misunderstand. The point.

Daniel Schmachtenberger 54:30
I'm so happy to hear you saying this, because I'm sure this is a conversation I would love to go deeper and understand the the distinctions between the lineage and group selection the way that you see them. But if I just even take the concept of group selection, as opposed to just individual selection and take a species like sapiens, and say, there was no such thing as an individual that God selected for that was not an effective part of a group of people and the tribe, the band was the thing that was being selected for. So there was fundamentally kinds of pro social behavior that were requisite. But then we get bigger than the Dunbar number only like yesterday, evolutionarily. And that whole, the whole evolutionary dynamics break, because that pro social behavior only worked up to that scale, when everybody could see everybody and knew everything, right? Like there's when we start looking at how do we solve collective action problems, you start realizing Well, how do we make some agreement field as to how nobody does the near term, game theoretically advantageous relative to each other long term bad thing, there has to be transparency mechanisms to notice it. So the beginning of defecting on the whole defecting on the law, the agreement fields of morals is the ability to hide stuff and get away with it. Well, you can't hide stuff in a tiny tribe very well. Even if

Bret 55:57
even if you can do it once, twice, 10 times sooner or later of height as your instinct you'll be revealed. And the cost will exceed what you've built up by. By pulling it off however many times you've done it.

Daniel Schmachtenberger 56:09
And so there's a forced transparency in that smallness of evolutionary scale. And when you start to get up to a large scale, and now there have to be systems where everybody isn't seeing everyone, and I'm smart enough, I can figure out how to play it and fuck the whole while pretending that I'm not hiding the accounting of it and getting ahead. That's the evolutionary niche for corruption for parasitic behavior. So one way I would describe, and as you've described on here before, if there's a niche with some energy, and it's going to get exploited, right? We have to rigorously close the evolutionary niches for human parasitic behavior, humans parasitizing other humans. And the first part of that is a kind of forced transparency that if someone were to engage in that it has to be known. And now the question is, that's all the versions of that we've explored at scale look like dreadful surveillance states. So how do you make something that doesn't look like a dreadful surveillance state? That also doesn't leave evolutionary niches for parasitic behavior that ends up rewarding and incenting sociopathy?

Bret 57:18
Absolutely. So a bunch of different threads. One, the Elinor Ostrom work is important, because it does point to the fact that you can scale these mechanisms up, in fact, selection has scaled up these enforcement mechanisms beyond a tiny number of people who know each other intimately. Now it hasn't scaled them way up. But it's proof of concept in terms of the ability to get there. And it's a model of what these systems might look like. The other thing, though, your your focus on corruption, I think is absolutely right. And one way to just detect how Stark The difference is, is the recognition of how many times in an average day you encounter bullshit, right? In other words, how many advertisements Do you encounter in an average, pre COVID day, let's say, right, these are all cases where somebody you don't know, or almost all of them are cases where somebody you don't know is attempting to manipulate you into spending resources differently than you would otherwise spend them. So this is an overwhelmingly dishonest interaction with your world. And there would have been some dishonesty for an ancient ancestor, you know, obviously, there are creatures that attempt to look like what they are not. But in general, one could see the world as it was, and the deception was the exception, not the rule. And in some sense, we live in a sea of bullshit, right? And we're so used to it that we don't even recognize that that's abnormal, that it is the the result of a gigantic niche that has opened up as a simple matter of scale as you point out, and that restoring a state where you can actually trust your senses. You can by and large trust the people who you're interacting with to inform you rather than lie to you would be a huge step towards reasonability.

Daniel Schmachtenberger 59:33
Oh, I really hope that we follow all the threads here, because this is getting so close to the heart of what we have to do. As scale increases, the potential for a cemetery increases. And as the asymmetry increases, the asymmetric warfare gets more difficult to deal with. So let's think about this in terms of Market theory. Let's think about an early hypothetical idealized market, like literally people just took their shoes and their cows and their sheep and their service offerings to a market and they looked at exchanging them. And then because trading cows for chickens is hard, we have some kind of currency to mediate a barter of goods and services, but we're talking about real goods and services. Maybe there's two people, maybe there's five people that sell shoes, there's not 5000 of them, and I can go touch the shoes myself, I can talk with them, I can see what the price is. And there is no hyper normal stimuli of advertising. It's like somebody's yelling from his thing. So there's a symmetry between the supply and the demand side, right? the supply side is a guy or a few guys selling something. And the demand side is a person or a family trying to buy something, and they can kind of tell each other's bullshit to some degree of cemetry. buyer beware becomes an important idea. But now when this becomes Nike, and then still one person, there's still a symmetry between supply and demand in aggregate, meaning, the total amount of money flowing into supply equals the total amount flowing out of demand. But this site is coordinated and the site is and if you don't have something like a labor union on all purchasers, we're like, all Facebook users are part of some union that puts money together to counter Facebook and lobbying and regulation, you have Facebook as like, a close to a trillion dollar organization against me as a person. And I'm still the same size person that I was in those early market examples. But there wasn't like a trillion dollar organization. And now, when that happens, manufactured demand kills market theory. And classical market theory, which is the the idea of why a market is like evolution, right? It's like some evolutionary process is that the demand is based on real people wanting things that will actually enhance the quality of their life. And so that creates an evolutionary niche for people to provide supply. And then the rational actor will purchase the goods or service at the best price and have the best value. But of course, as soon as we get to a situation where, and you look at dinner reality and all the behavioral economics, saying the whole economics is the rational actor doesn't exist, we end up making choices based on status that's confirmed with a brand based on the compelling Miss of the marketing based on all kinds of things that are not the best product or service at the best price. But you also get that I want stuff that will not increase the quality of my life, I desperately want shifts, because I was the demand was manufactured into me. So it's not an emergent, authentic demand that represents collective intelligence. It's a supply side, saying I want to get them to want more of my shit. And I actually have the power to do that using Applied Psychology like actual. And as soon as you get to split testing, and the ability to AI split test a gazillion things. We're talking about radically scientifically optimized psychological manipulation for the supply side to create artificial demand and then be able to fulfill it. And and most of that ends up being of the type that is actually bad for the quality of the life of the people, but you have the plausible deniability, they're choosing it, hey, I don't want to be patriarchal and control what they're doing. The people are choosing it, I'm just offering the source of supply that they're wanting bullshit. That's like offering crack to kids. And then when they come back for more of it, like saying, hey, so this, that was one of the threads I wanted to address.

Bret 1:03:41
Well, I love it back in must have been 2013, when game B was actually a group of people who met in a room and talked about things. One of the points that I was making in that context, was this inherent asymmetry around unionization. And that the problem is unions have gotten a bad rap because of the tight Association, cognitively, that we have with labor unions, right? We think of unions and labor unions as synonymous, but union is actually a category, it's potentially a very large category. And effectively, management always has the benefit of it. The question is, will workers have a symmetrical entity? Right? That's the labor case. But you can make the same case with respect to you know, banking, credit unions don't work, they're very bank like, but if they were structured in such a way to actually, you know, unionize, people who utilize the bank, could be highly effective could be a complete replacement for the insurance industry, which doesn't even make sense in a market context. But as a risk pool, you could do a very effective job. So anyway, yes. The The question is, how do you scale up the collective force, and especially how do you do it in light of the fact that the entities that are already effectively unionized, see it coming. And they disrupt it with all of their very powerful tools. And so Well, anyway, go ahead.

Daniel Schmachtenberger 1:05:19
Want to say the beginning of an answer to that? Because I think it brings us to what you've been largely exploring in this show of late of the breakdown of democracy and open society, and what do we do about that, and how that relates to breakdown in culture and breakdown and market, we can look at those the relationship between those three types of ethics. So a way of thinking about what the architectural idea of a liberal democracy is, and why say, the founders of this country set it up not as a pure laissez faire market. But as a,

Daniel Schmachtenberger 1:06:04
as a state that had regulatory power and the market together, was, the idea is that a market will provision lots of goods and services better than a centralized government well, so let's leave the market to do the kind of provisioning of resource and innovation that it does well. But the market will also do a couple really bad things, it will lead to increasing asymmetries of wealth inexorably, this is what Piketty is data showed and but it's just obvious having more money increases your capacity to have access to financial services, and you know, you you make interest on debt and on compounding interest on wealth. And so you end up getting a power law, distribution of wealth. So then a few people in just the market dynamic would be able to have way outsized control over everyone else against everyone else's interests. And the market creates opportunities for things that are really bad, we all know that, like, we want there to be a thing called crime where you don't where even though there's a market incentive for child sex trafficking, and whatever else, we say, No, we're we're going to create some rule of law that binds that thing, and not just have market drive it. So the idea is that we create a state that we actually give a monopoly of violence to so it has even more power at the bottom of the stack of what power is than the top of the economic power law distribution. So the wealthiest people and the wealthiest corporations will still be bound by this rule of law. And the rule of law is an encoding of the collective ethics of the people, right? The ethics are the basis of jurisprudence. And there is some kind of democratic process of getting to say, what is it that we consider the good life and important that we want and trying and rule of law, we give that a monopoly of violence. And really, then the goal of the state is to bind the predatory aspects of market incentive while leaving the market to do the things that it does well. But pretty much every law is where someone has an incentive to do something, which is a market type dynamic, that is bad for the whole enough that we make a law to bind it. Okay, so the purpose of a state is to bind the predatory aspects of a market that only works as long as the people buying the state. And the people buying the state if you have a government of four, and by the people of an educated populace, who are who had a quality of education, that we're capable of understanding all the issues upon which we are governing and making law and a fourth estate, where the news that they are getting is of adequate quality and unbiased enough that they're informed about what's currently happening. For if you think about that, that's what a republic would require. And you realize that both public education and the fourth estate have eroded so badly for so long. It's not that we're close to losing our democracy, it's dead, we don't have a republic, we have a permanent political class and a permanent economic lobbying class. And the people who aren't really actively engaged in government in any way at all beyond maybe jury duty now and again, if they can't get out of it. And if the people to be engaged in government in any meaningful way had to tell the do what they think should be done about grid security and energy policy or tell the god what should be done about nuclear first strike policy or tell the Fed and Treasury what they think about interest rates. They don't they have no fucking idea how to have a governance formed by the people. They don't have that education. They don't have the the media basis. So if the culture, if the people can't check the state, then the state will end up getting captured by the market. And so you'll end up having the head of the FDA be someone who ran a big drug or a big ag company in the head of the God being somebody who ran Lockheed or some military industrial complex manufacturer, you'll have just lobbying just straightforward lobbying gets paid for by somebody who's a get paid for those who have the money to pay for lots of lobbyists. And so then you end up getting a crony capitalist structure which is worse than just an evil market because now it has the regular Worry apparatus of rule of law, monopoly of violence backing up the market type the dynamics. So then we say, Okay, well what do we do here. And we see that civilizations fail towards either oppression or chaos, right? Those are the two fail states, they fail towards oppression. If trying to create some coherence happens through a top down forcing function, they fail towards chaos, if not having enough top down forcing function, everybody kind of believes whatever they want, but they have no unifying basis for belief. And so then they will end up going into they'll, they'll balkanize, they'll tribalism, and then the tribal groups will fight against each other, if you don't want to, so and so either. We keep failing towards chaos, which we can see is happening in the West and in the US, in particular right now. And then China, which is happy to do the oppression thing and oppression beats chaos and war, right? Because it has more ability to execute effectively, which is why China has built high speed trains all around the world, and we haven't built a single one in our country.

Daniel Schmachtenberger 1:11:05
So either we lose to China in the 21st century, and oppression ruins the 21st century, or we beat China at being China mean being a depression or it's like fuck, those are both failure modes. What is the what is there other than oppression or, or chaos is order that is emergent, not imposed, which requires a culture of people who can all make sense of the world on their own and communicate effectively to have shared sense making as a basis for shared choice making the idea of an open society is that some huge number of people can all make choices together a huge number of people who see the world differently and are anonymous to each other, not a tribe. That was an enlightenment era idea, right? born out of the idea that we could all make sense of the world together born out of the philosophy of science and the Hegelian dialectic that we could make sense of base reality. And that we could make sense of each other's perspective dialectic, find the synthesis, and then be able to have that be the basis of governance. So what what I think is, this is not an adequate long term structure, because we can talk about why Tech has made nation state democracies obsolete. And it's just not obvious yet, but it has. But as an intermediate structure, the reboot of the thing that was intended has to start at the level of the people at culture, and that collective sense making and collective good faith dialogue. Because without that, you can't find state. Without that you can't find market incentive. Okay, I love

Bret 1:12:33
this riff of yours. Okay, I think there's a tremendous amount that's really important. And the synthesis is super tight. I know people will have a little bit of trouble following it. But I actually would advise them to maybe to go back through it and listen to it again, because it's right on the money. As far as I'm concerned, there's one place where I wonder if it doesn't have two things inverted. So you talk about the two characteristics that are necessary in order for what did you call it liberal democracy or whatever it was that you used as a moniker to function, one of them had to do with the idea that the state was big enough to bind the most powerful and well resourced actors. And the second was that the people have to be capable of binding the state. Now, I understood you to say that what failed first, was the people's ability to bind the state, is that correct?

Daniel Schmachtenberger 1:13:32
I'm saying that's this foundation of the stack that we have to address the failure with recursive.

Bret 1:13:38
So as I see it, what happened was the power, the fact that there is always corruption, it's impossible to drive it out completely. The corruption self enlarges the loopholes, and becomes subtle enough that it's hard to see directly. The most powerful actors suddenly got an infusion of power, and we could trace down the cause of it. But let's just say somewhere in recent history, the most powerful actors became more powerful than the state. And what they did with that power, was they unhooked the ability of the state to regulate the markets. I believe the reason for this was that each individual industry had an interest in having its regulations removed in order to create a bigger slice of the pie for it. And so effectively, what you had was each industry agreeing to unregulated every other industry, like you can regulate, if I have a pharmaceutical company, right and you're an oil company, and you want to make money but you have to be able to fuck up the atmosphere to do it. And I want to make money giving people drugs that they shouldn't have. And you know, corrupting the, the FDA, then we'll partner and so you what you got was many The industry is partnering to unhook the ability of the state to bind the market. But one of the things that they had to do in order to make that work was they had to eliminate the ability of the people to veto. Right. And so this is where we get this incredibly toxic duopoly that pretends to do our bidding, and pretends to be, you know, fiercely oppose the two sides of it. But in fact, the thing they're united about is not allowing something else to compete with them for power. So it's, you know, the wolf in sheep's clothing is in charge of the thing that is supposed to be protecting us from wolves. In any case, we don't have to go too deep there. But

Daniel Schmachtenberger 1:15:41
this, this is actually super important. Go for it. This is related to the thing we said about as the market as a whole gets bigger, then the individual consumer says an individual consumer, but the supply side, the company gets much larger. as that happens, the asymmetry of the war between them of the game theory between them gets larger. And so a manufactured demand becomes more intense thing. Well, the same thing is true in terms of the market capacity to influence the government and the market government complexes capacity to keep the population from getting in the way of the extraction. And so there's a heap of mechanisms that happen. And there's not like five guys at the top who are coordinating all this. It's a shared attractor or incentive landscape that oriented. Yeah, largely emergent. Yeah. And where there are people conspiring, it's because their shared incentive and capacity to do so. Which so the conspiracy is itself, an emergent property of the incentive dynamics, which then in turn doubles down on the types of incentive dynamics that make things like that succeed. So okay, let's take a couple examples. If people haven't read it, they should all read at least a Wikipedia page on public choice theory, a school of libertarian thought that critiques why representative democracy will always break down, that the founders of the US basically said this, which is, Alright, we'll come back to cemetery for a moment. At the time that we were creating the structure of liberal democracy, the size of choices, and the speed of them was smaller and slower, such that the Town Hall was a real thing. And when the Town Hall is a real thing, the coupling between the representative and the people is way higher, right, because the people are actually picking representatives in real time that are really representing their interests. And they get to have a say in it, there was a statement by one of the founders of the country that voting is the death of democracy, because the idea is we should just be able to have a conversation that is good enough that we come up with a solution, and everyone's like, that's a good idea. If we can't, then we vote. But that means that some big percentage close to half the population feels unhappy with the thing that happened. And so it's a sublimated type of warfare. It's a sublimation of violence, but it leads to a polarization of the population. And so the goal is not voting. Voting is the last step of when we couldn't just succeed in a better conversation in specking. out, what is the problem? What are the adjacent problem? What are the design constraints of a good solution? Can we come up with a solution that meets everybody's design constraints as best as possible?

Bret 1:18:29
Okay, so I disagree with this at one level, as I'm sure you will, as well, I'm not sure but I suspect, but I love something about the formulation that voting is itself a kind of failure mode. Right? That ideally speaking, if you had a well oiled machine, if you had a, you know, military is the wrong analogy here. But let's say you had a, you know, a ship of people fighting impossible odds to make it back to safe harbor, right? The point is, you really shouldn't want a system in which you're voting between two different approaches to the problem, you should want a discussion in which everybody by the end is on board. And if you tried to do that, in civilization, we'd never accomplish anything, right? You effectively have to give the majority the ability to exert a kind of tyranny over the minority in order to accomplish the most basic stuff. But that's because the system is incapable of doing what a better system would do, which is to say, this is the compelling answer, and you're going to know why by the time we decide to do it.

Daniel Schmachtenberger 1:19:41
Wait, there's a cemetery here between the conversation that we had about the market incenting people who focus on the opportunity and not the risk sets that it actually suppresses those who look at the risk. Once you say, hey, there's always going to be somebody talking about a risk that isn't gonna happen. We'll innovate our way out and that becomes the story. Now. You plausible deniability to always do that. Once you say there's no way to get everybody on the same page, we can't do that it'd be too slow. Now, I don't even have any basis to try. Right? And so I don't ever even try to say, what is it that everyone cares about relative to this? So I even know what a good solution would look like to craft a proposal. No, we're gonna vote on the proposition having never done any sense making about what a good proposition would be. And that's just mind blowingly. Stupid, right? And so then who's going to craft the proposition, a lawyer mortgage paid for by some special interest group? And so now, so most of the time, what happens is, you have some situation where one thing that matters to some people has this proposition put forward that benefits, it's simply in the short term, but it externalizes a harm to something that matters to other people. But ultimately, all of it matters to everybody just differentially weighted. And how do we put all those things together? So, okay, we're going to do something that's going to benefit the economy, but harm the environment, well, everybody cares about the economy, and everybody cares about the environment. But if I put forward a proposition that says, in order to solve climate change, we have to agree to these carbon emission controls that China won't agree to, and therefore China will run the world in the 21st century, and we all have to learn Mandarin or be like the Uighur or something. Okay, well, now I have a bunch of people who, because they hate the solution space, because it harms something else they care about, don't believe in climate change. It has nothing to do with not believing in climate change, not caring about the environment, is that they care about that other risk so much as well. But if I said okay, well,

Bret 1:21:36
let's look at it's a negotiation tactic is what you're saying that at the point that you want x prioritized over why you'll potentially you'll descend into a state in which you'll make any argument that results in that happening, including Why doesn't exist.

Daniel Schmachtenberger 1:21:54
Exactly, because I'm so motivated by this other thing. And the solution has a has a theory of trade offs built in that is not necessary. Sometimes the theory of trade off is necessary, but oftentimes, a synergistic satisfier could be found. But we didn't try in the same way that a way to move forward with the opportunity. without the risk could have happened, we could have found a better way to do the tech that internalized that externality. We just need to try it a little bit more. But there isn't the incentive to do it. So let's say we said no, we don't care about climate change by itself. We care about the climate. And we care about the economy. And we care about energy independence, and we care about geopolitics. And we're going to look at the adjacent things, we're making a choice, and one of the areas necessarily affects the other area. And we're going to bring those design constraints together, and we say what is the best choice that affects these things together, then we could start to think about a proposition intelligently. We don't do this in medicine, either we make a medicine to solve a very narrow definition of one molecular target of a disease that externalized The side effects in other areas without addressing upstream what was actually causing the disease. And then the side effects of that med end up being another med and then all people die on 20 minutes of I intragenic disease. So in complex systems, you can't separate the problems that way, you have to think about the whole complex thing better. And so. So the first part of fixing one part of fixing democracy that we have to think about is we have to define the problem spaces better, more complex. And we have to be able to actually have a process for coming up with propositions that are not stupid and intrinsically polarizing. Because almost no proposition ever voted on gets 90% of the vote, it gets 51 fucking percent of the vote, which means half of the people think it's terrible. And so what that means is you care about the environment, I care about the economy on Proposition A, well, you petition to get this thing to go through because you care about the house there. But I think that you're making my kids core. You're my fucking enemy now and I'll fight against you. Now all the energy goes into internal friction fighting against each other, and any other country that's willing to be autocratic, and force all their people on the one side, we'll just win. And we will increasingly polarized against each other over something where we could have found a more unifying solution.

Bret 1:24:20
Now, this is fascinating. For one thing, you blazed by it there, but I think so there's a place where Jim rut tells me that someplace that you and you and he overwhelmingly agree also, but there's a place in which you and he have hung up, where he says that you believe that a properly architected system can do away with the trade offs? No, right? Right. I think I just heard you give the answer that he must have understood to be that but wasn't it? Am I right? The answer. There are lots of times when you don't see a trade off, because you have two characteristics, both of which are Have optimal and you could improve them simultaneously. And so it looks like there's no trade off between them. If you push it far enough, you'll eventually reach the efficient frontier where you do have to choose. But if you're not near the efficient frontier, there's no reason to treat it as a trade off. Is that?

Daniel Schmachtenberger 1:25:14
Yes, I'm not saying that we get out of having constraints. I'm saying we can do design by constraints much better than we currently do. And so I'm saying that there's a lot of things that we take as inexorable trade offs that aren't.

Bret 1:25:31
Well, so you and I will have to chase this down at some point, my argument will be any two desirable characteristics have an inherent trade off between them, even if you never see it? Right? There are reasons you wouldn't see it. But that if you push these things far enough, you'll find that there are no desirable things that can be components of the same mechanism that will not exhibit a trade off relationship. Right?

Daniel Schmachtenberger 1:25:57
Initially, I don't agree with that at all. But I'm sure you've thought about it a lot. So I'm curious why you say it.

Bret 1:26:02
Well, let me give you let me give you the example. I used to battle, my friend, Scott picure. picker over with this, which is he said, Why can't you make a car? That's the fastest and the bluest. Right? And, you know, the first time I heard that was like, Well, okay, maybe blue is trivial enough, but it's not. In fact, if you wanted to make a car that was the fastest and by fastest, let's say, the fastest accelerating, well, you're going to have to decide how to paint it. If you also decide that there's some color of blue that is bluest, and you want the car to be that color, well, then it has done a lot of the choosing of what paint you're going to put on it, at the point you decide to paint it that color, that paint will have components that will waste something right the chances that the bluest whatever you define that to be is also the lightest and has the best laminar flow characteristics are essentially zero, right? Because there are an infinite diversity of colors. And they will be made out of a wide variety of materials. And the chances that the blue just happens to be the one that is lightest and has the best you know slipperiness relative to the wind are going to be vanishingly small. And that means that if you want to make truly the fastest car, its its color will be chosen by whatever paint has the best characteristics. And if you want to make it the bluest as well, you'll make some tiny compromise, that will, you know, probably not matter to you, but it's there. So the trade off is there, even if we don't see it. But here's the thing, Daniel, I discovered many years after my argument with Scott was long since put to bed that I was right about this. And the way I found out was that there is a case where the Navy wanted to set the time to climb record for an aircraft, and they took an F 15. And they souped it up a little bit. And in order to set the basically the vertical climb rate of this aircraft, they stripped the paint off it and so if you look at pictures of this aircraft, in its, you know, its record setting run, it isn't any particular color, it's many different colors, because effectively you've got the bare metal underneath, with the paint stripped off it to save however many pounds of paint they were able to remove.

Daniel Schmachtenberger 1:28:18
Okay, there are three points that come up to address my initial thoughts on this here. So one is with this particular case of a car, the difference between the blue and the optimal color might be at the boundary of measurement itself. Yep. And so while it's true that there it might not be a perfect optimum of both at the level of like a nano scale optimization, it is irrelevant to the scale of choice making for the most part. And when we look at something higher 100%. And when we look at something like Tesla cars, that became faster off the line than Ferrari's and safer than Volvo's and greener than priuses. At the same time, you could see that ground up design do just doing a better job of ground up design was able to optimize for many things simultaneously, so much better. Now, had they made it less comfortable. Could it be faster still Sure, of course. So it's optimizing for a product of a bunch of things together, but still in a whole different league than things had been previously. Now, boy,

Bret 1:29:37
this, this is beautiful, okay, because this is exactly what I was hoping for. Okay. This is a question of us tripping over each other's language. Jim misunderstood what you were saying, right? And he asked me about it, and I said, Yeah, Daniel can't be right about that. If he's saying what you think he's saying, but of course, it wouldn't make sense that you would think that you could so your point about this being triggered You're in complete agreement with me. And I suspect it would take nothing to get Jim to agree to that formulation. As well,

Daniel Schmachtenberger 1:30:08
we there's a difference. There's one more thing I have to say here, okay? Of course, I'm not pretending that thermodynamics don't exist, right. And once you get down to the, the quantum scale arrangement of the thing that orientation in one direction doesn't have effects on other things have

Unknown 1:30:25
done. Yep.

Daniel Schmachtenberger 1:30:29
There's a difference also, between the blue and fast are two different preferences that are arbitrary that both wants to be associated with a car that don't have some intrinsic unifying function. And we can say blue is a thing that reasonable to be preferential about color. Whereas I would say that there are some characteristics that have a synergistic effect that increasing one increases the other one, because of the way they are part of a overall increase in system integrity. And so synergy is the key concept I'm trying to bring about here, which is behavior whole systems more than the sum of an unpredicted by the parts taken separately. So when I say I'm looking for synergistic, satisfiers, the idea that I have X amount of input, and that input has to be divided between these various types of output, and it's linear is nonsense. I can have IQ, I can have X amount of input and have something where the total amount of output has increased synergy based on the intelligence of the design, or the question of how do we design in a way that is optimizing synergy between all the things that matter becomes the central question.

Bret 1:31:50
Yes. Which is, of course, the central question that selection must be dealing with in generating complex life. And, you know, I don't, again, I don't think we have a hair's breadth of difference on what we turn out to believe about this trade off space. But what I would say is, and I don't want to drag the audience too far down this road is probably not worth it for what we need to do here. But the benefit of being able to say, so let's take your example of there are certain characteristics that will co maximize, not really, because of the following thing, let's say that we figure out what color is best for making the fastest car. And then we say, Well, I want to maximize gray 37. And speed, now I can do it, I can maximize gray 37. And speed because it just so happens that gray 37 is the color that has the best characteristics for speed, right? But then the point is you can't separate these two things, whatever characteristic it is, you're actually maximizing. You've just found two aspects of it. So your point about synergy is that perfectly aligned characteristics, we could describe that joint, that fusion of those two things is one thing, and we could maximize it, right. But then if we take the next one over, right, the next characteristic that we want to add to the list of things, then again, we're back in trade off space. So my only point here is that there is a value in order to be able to get the maximum power out of a trade off theory. What we want to do is make it minimally complex and the ability to say, every two desirable characteristics have a trade off between them. The real question is the slope, or the shape of the curve, right? And that many of these slopes and shapes mean, we will see no meaningful variation on it, because one side is a bargain. And we will always see that manifest, right? That's the reason we don't see trade offs everywhere, is that in some cases, a trade off is so dumb, that we don't see anybody exercising variation, everything is made the same decision.

Daniel Schmachtenberger 1:33:59
Yes, I and I think for all practical purposes, we agree that being able to make a Tesla that is safer than a Volvo and faster than a Ferrari and greener than a Prius is a possibility and that we can if we apply that to all of the problems in the world, we could do a fuck ton better job. Yeah. I think we also agree and I love the last point that you made that to the degree that two things can be simultaneously optimized, they can be thought of as facets of a deeper integrated thing. Yep. Okay, so now to answer the way that I actually think about it, though, this is irrelevant if people disagree it doesn't matter at all to the earlier point I have to wax mystical moment. When Einstein said it's a optical delusion of consciousness to believe they're separate things there's in reality, one thing we call universe and everything is a facet of it. If I look at The real things that we have theory of trade offs between the space in the social sphere and the associated biosphere that we're a part of. So let's say we talked about in the very beginning of our conversation individually, what would optimize my individual well being, and what would optimize the individual and what would optimize the well being of all humans, I believe that I only find that those are differently optimized. If I again, take a very short term focus, if I take a long term focus, I find that they are one thing because the idea that I'm an individual, and the idea that humanity is a separate thing is actually a wrong idea. They're facets of an integrated reality. And that if I factor all of the things that are in the Unknown, Unknown set over a long enough period of time, they were simultaneously optimized. And this is the essence of dialectical thinking, is looking for the thesis and the anti thesis and not voting between thesis and anti thesis, but seeking synthesis that set a higher order of integration and complexity.

Bret 1:36:00
Totally agree. And, you know, so I don't know how many people will be tracking it. But, you know, effectively saying on a indefinitely long timescale, these things converge is an acknowledgment that we are not talking about design space, when we make this recognition, right, it's more like projectory. And that is perfectly consistent. And frankly, I think, if everybody understood, at some level, the kind of picture we're painting, people would be really comfortable with the degree to which it doesn't do exactly the thing they most hope it will, right. In other words, that level of compromise is small, right? What you

Daniel Schmachtenberger 1:36:44
would compromise in a healthy democracy even was tolerable, even though that was nowhere near as optimal system as we could develop.

Bret 1:36:53
Okay, there's a point a number of minutes back that I want to return to, and I want to drop an idea on you. It's actually a place where something you said caused me to complete a thought that I've been working on for some time. So the thought as it existed, is that markets are excellent at figuring out how to do things. And they are atrocious at telling us what to do. In other words, they will find every defect in human character and figure out how to exploit it if you allow them to do that. But when you have a problem that you really want solved, right? How can we make a phone that doesn't require me to be plugged into the wall allows me to get a message across a distance to report an emergency, whatever, markets do a better job than we could otherwise do, of figuring out what the best solution is? And so in some sense, the question is, how can we structure the incentives around the market so that markets only solve problems that we want them to solve, but they can be free to solve them? Well, and what what I think I realized in this conversation here is that in some sense, the role of the citizenry in a democracy is to discuss the values that we want government to deploy incentives around. In other words, the people by deciding what their priorities are, what their concerns are, which problems are top of the list to be solved, and which ones could take a backseat, that that's the proper thing that we are to be discussing, that the role of government freed from corruption, would be to figure out what incentives will result in the best return on our investment, structuring the incentives of the market and then the market can be freed to solve the narrowest problems on that list. And I think we fail at every level here. But from the point of view of what we're actually shooting for, I would say it's somewhere in that neighborhood, that division of labor between the citizens the apparatus of governance and the market.

Daniel Schmachtenberger 1:39:07
I'm suffering a little bit here because there's like 10 simultaneous threads that I really could address that are important and I know we're gonna open up more and starting I it would be really fun to go through the transcript of this and come back to the most important for it

Bret 1:39:20
might be worth doing actually. So

Daniel Schmachtenberger 1:39:24
first, I want to say something against heterodox market theory is I don't think the market is the best system for innovation of a known what. And I think world war two in the Manhattan Project is a very clear example and the Apollo project

Bret 1:39:45
on our on our failure at fusion, I would say that the the point you're about to make, to me, fusion would be our top priority because it's the only plug and play solution to a large piece of our problem and the fact We decade after decade are awaiting of a proper fusion solution says, you know, despite the fact that the market could potentially solve it, the problem is the investments are too large on the front end, and the reward is too delayed for the market to actually even recognize the problem correctly.

Daniel Schmachtenberger 1:40:18
venture capital is not going to put up the amount of money that a nation state can for the amount of time that's necessary. And when you look at the very largest jumps in innovative capacity, a lot of them happen by nation state funding, not market funding, and then a market emerging in association with kind of government contracting. And so if we like, if we look at why the Nazis were so technologically farther ahead than everyone else, going into World War Two, with the Enigma machine, and the beginning of computing with the v2 rocket, it was not a market dynamic. It was a state dynamic, where they invested in science and technology development for a long time, which is why this tiny little country with limited industrial supply capacity had more technological advancement than the Soviets or the US. And it was, it was our ability to steal their shit and rip it off and then be bigger than them. That was a big part of how we were able to succeed in the war effort. And so that's a clear example that like computers were developed by a state, not the market, right? Well, whoa,

Bret 1:41:21
hold on a second. I want to be careful, because I don't want to falsify something that isn't false. I again, think this is a place where our mappings, or at least the language surrounding them, is going to upend us because this sounds like a place where a government is capable of generating a massive incentive to cause a problem to be solved that the market won't even find on its own. Right. So that does not strike me as inconsistent with what I was just saying the state recognizes there's a problem creates an incentive big enough to find the solution. And that incentive can be big enough to cause people to get different degrees, and they would otherwise seek and

Daniel Schmachtenberger 1:42:03
better use cases it wasn't like, so let's take the Manhattan Project. It wasn't private contractors. That solved it, because the government had made the incentive, it was actually government that solved it, it was government employees. And so this is a this important distinction. NASA was not a private space contracting thing that did the Apollo project, it was a government project. So I would say the largest jumps we ever made in tech did not happen in the market, for the most part,

Bret 1:42:33
well, so then, I guess the test of your falsification. Here is the following question. If the Manhattan Project had consisted of a state, yanking people out of their beds, and standing over them with rifles, would it have worked? I mean, it may be, you know, the Russian version is closer to that. But I think the point is, you still have a, you have a system of incentives, correctly solving a problem that the market would not have found on its own, and no entity in the market would have been big enough to solve. So I still see it as consistent. But you might, you might convince me otherwise, especially if it turns out that a negative incentive would be just as effective at creating the solution.

Daniel Schmachtenberger 1:43:31
there's a there's a story that people don't innovate well, under duress, the innovation requires executive function and prefrontal function. And if they're too limitedly oriented, they won't innovate well, which is one of the reasons why we need an open society. And I think there's probably some truth to this, but less truth than we would hope. I believe it was called the Shure oska system, which was a Russian. Basically, prisoner of war type camps, it had scientists that were doing real innovation, up to, you know, early Sputnik, like work. So we know that people under rifle duress can't innovate. We know that people conscripted by draft into an army can actually innovate on behalf of the military. Now, I think that it's true that something more like a market will explore more edge cases that are not known what's and come up with interesting things. Whereas the centralized thing can do a better job sometimes of existing ones that require very high coordination. Because if you look at the Manhattan Project, the scale of the budget and the scale of coordination, no company has that and a bunch of companies competing for intellectual property, whatever, it wouldn't have worked, right, right. One of the reasons I bring this up is because there's a whole bunch up You mentioned fusion, whether it's fusion or whether it's thorium or whether it's closer to room temperature, super conduction, or any of the things that could possibly generate, whether it's 65%, efficient photovoltaic through nanotech. There's a bunch of things where we're like, we kind of know the science that could lead to the breakthrough, but the level of investment just isn't there. And I think there's a heap of examples like this, where the percentage of the budget of the national budget that used to go to r&d has went down a lot, and it shouldn't. And the Apollo project was kind of the last thing of its type. And then the government starting to shift to government contractors started to be a source of massive bloat, where the government contractors had an incentive to just charge whatever the fuck they wanted, which is why then Ilan could beat Lockheed and Boeing at rockets so much cost wise, because then in that situation, he didn't have to do the fundamental innovation on rocketry, he could just out compete them at market incentive. And then that could create enough money for iterative innovation, I think fundamental innovation of certain scales does require larger coordination. And markets make easy.

Bret 1:46:10
Okay, so then I want to modify what I said, because you've convinced me I didn't have it right in the initial one. So the the point then is you have to extend the governmental structure so that it can deal with two types of market failure, one surrounding the natural system of incentives, which will cause you to innovate things that do net harm, for example, and the other is a failure, where the scale of the market is not sufficient to solve certain problems that are in our collective interest to solve.

Daniel Schmachtenberger 1:46:42
Yes, and we don't want to give the government that much power, because we don't trust that kind of authority. But that's because the people aren't checking the government, which comes back to the thing that we talked about earlier. And now this becomes one of the central questions of the time is what is the basis of legitimate authority? And how do we know and what is the basis of warranted trust, because we all know what it means to have trust that isn't warranted we everyone who disagrees with us, we think that their trust is warranted, right? Like, if we're on the left, we think people who believe in we trust Trump it's unwarranted. And they think that the people who trust the FDA or vaccine scientists or the CDC of trust, it's unwarranted. We also know that legitimate authority, the idea of legitimate authority is so powerful to be able to be the arbiters of what is true and what is real, that anyone who is playing the game of power has a maximum incentive, however successful they are to be able to capture it influence that for their good. We also know that it's possible to mislead with, with exclusively true facts that are cherry picked or framed. So I can, I can cherry pick facts on one side or the other side of a Gaussian distribution and tell any story I want, that will make it through a fact checker. So fact checking is valuable, but not even close to sufficient. So I can lie through something like the Atlantic as well as I can lie through something like Breitbart through different mechanisms for different populations.

Bret 1:48:09
Yeah, this is a super excellent point as well, that a fact checker errors in one direction and the, if you can build a falsehood out of true objects that have been edited, then the fact checker won't spot it. So love that point.

Daniel Schmachtenberger 1:48:27
And so I can do a safety analysis on a drug. And I'm not looking at every metric that matters, I'm looking at some subset of the metrics. And it might be that it's safe on those metrics, but in but all cause mortality increases, life expectancy decreases, but I only did the safety study for two years. So I wouldn't notice that. So I can say, No, methodologically This was perfect. And sound, it always just also doesn't matter because it wasn't I wasn't measuring the right things,

Bret 1:48:55
right. And so this also, basically, what you have just said, means that the replication crisis can be understood as a mechanism for generating data which can be carried picked to reach any conclusion you want about the effects of this intervention or that intervention, right? Because effectively what you have is the ability to choose between experiments where sampling error will result in both outcomes being evidence somewhere.

Daniel Schmachtenberger 1:49:26
This is another one of those is a conflict theory or information or mistake theory thing is I can intentionally manipulate an outcome that looks methodologically sound, and then say, Oh, we just didn't know those factors, right? I'm not saying that whether that's happening or not, it certainly can happen. Okay, so now we get back to so what is the How do you have a legitimate authority that has the power of being the arbiter of what is true and real and all the power that's associated and have it not get captured by power interests is a very, very important way. And how in the name of the Bible and Christian dumb and Jesus saying let He who has no since cast the first stone did we do the Inquisition, right like weird mental gymnastics, by which the authority of that thing was able to be used for the power purposes of the time. And so now when you start to have increasing polarization between the left and the right, and historically more academics being left leaning into social scientists, the social sciences, being so complex that you can cherry pick whatever the fuck you want, and do methodologically sound and yet still miss representative stuff. Then you say, is that actually a trustworthy source? And then we say, Okay, well do we want a bunch of wacky theories going out over Facebook and Twitter and whatever do we want to censor it? Well, if we censor it, who is the arbiter of truth that we trust? If we don't censor it, we're appealing to the worst aspects of everyone and making them all worse in all directions, like those both suck so bad, and that's the oppression or chaos, right? And the only answer out of the oppression or chaos is the comprehensive education of everyone in the capacity to understand at least three things. They have to increase their first person, second person and third person epidemics. Their third person epidemics is the easiest philosophy of science, formal logic, their ability to actually make sense of base reality through appropriate methodology and find appropriate confidence margin. second person is my ability to make sense of your perspective, Can I steal man where you're coming from Can I inhabit your position well, and if I'm not oriented to do that, then I'm not going to find the synthesis of a dialectic, I'm going to be arguing for one side of partiality, harming something that will actually harm the thing I care about in the long run. And then first person can I notice my own biases, and my own susceptibilities, and my own group identity issues, and whatever well enough that those aren't the things that run me. When I look at kind of the ancient Greek enlightenment, the first person was the stoic tradition. The second person was the Socratic tradition, the third person was the Aristotelian tradition, there's a mirror of all those in modernity, we need a new cultural enlightenment now that where everyone values, good sense making about themselves about others about based reality, and good quality dialogue with other people that are also sense making to emerge to a collective consciousness and collective intelligence that is more than our individual intelligence, and with so that we have some basis of something that isn't chaos, but that also isn't depression, because it's emergent more than imposed. So it's like it's cultural enlightenment, or bust as far as I'm concerned. All right.

Bret 1:52:44
So I don't disagree with you. Fundamentally, I believe this is a place where when I say my version of this, which is much less sophisticated in some ways, and focused elsewhere, but when I say my version of it, I lose people, because my version of it is something like, what we need to do is doable, we can see the trajectory from here, you can't see the objective, but you can see the direction to head and it will take three generations to get there. Right? I agree what you're describing, you couldn't just simply take that curriculum and infuse it into any system we've got and have any hope of people learning it or give a shitting giving a shit about it or whatever, it wouldn't work. So you have to build the scaffolding that would allow a population to be enlightened in this way, such that the governance structure you're imagining might arise out of it could flourish. But let's put it this way, it's at least at least three generations out before you had gotten there, even if you started doing things right now. And so what I try to say to people, in order that they don't completely lose interest in the possibility of a solution, because it's too far out is things can start getting better right away, we are not going to live to be in that world. That is the objective. And even if we did, we would never be native there. Right? Our developmental trajectory will have been completed in a world that doesn't function like that. And so you know, you, you can be happy as an expat, but we would be experts in the world we're trying to create, and that's fine. You know, if our grandchildren or great grandchildren were native there, and we could be experts there, that that would be a perfectly acceptable solution. But I think in general, people have the sense that a solution sounds like something that we could have in the next few years, and I just don't see the possibility of it.

Daniel Schmachtenberger 1:54:53
No, you're gonna see things, anything that can be implemented quickly. You want to read team and say either Does it fail? Or where does it externalize harm? And also what arms race does it drive whoever doesn't like it. And if you factor what arms race, it drives where it externalizes harm and where it fails, you'll get much less optimistic about most of those things. And if you don't go into despair, you'll start thinking long term, and things that convergent long term direction. And when you start to think about that, the thesis and the anti thesis are both not true. They have partial truth, but they are not actually true synthesis is in the direction of more integration of truth and still not true. But in the direction of, if I optimize for one of these, it will externalize harm in a way that messes the whole thing up, right. And that's why there's there's a forcing function of the failure modes on both sides. That's why it's important to look at oppression and chaos and say these both create failure modes. So what is it that doesn't orient in either those directions, it's not more power to authorities. It's not more pure libertarianism, it's something that's outside of that access,

Bret 1:56:04
or it is going to involve the equivalent of negative feedback, right? In other words, right thermostat works by virtue of not embracing it being hot or cold, but by pushing it in the right direction as it diverts one way or the other. So I very much like your point about synthesis here. Just to make it clearer. synthesis is two things even linguistically speaking, we can talk of a synthesis, right, which is an object, you could write it in a book at a synthesis between several different concepts could exist in a book. Incidentally, that's sort of what I see myself doing in biology is synthesis. But your point is the most important aspect of synthesis is it is a process or right and so that process is the thing that takes these competing failure modes, and rescues from them something that suffers neither consequence and heads towards optimality. So I believe we have to get good at.

Daniel Schmachtenberger 1:57:10
Yeah, so synthesis is an ongoing process. And let's say I have some bits of true information in a thesis and some bits in the anti thesis. So the synthesis will have more bits than either of them higher order complexity, but it will still have radically less bits of information than all of reality about that thing. The model is never the thing, right? It's just, it's the best epistemically we can do at that moment. So now I want to go back to the earlier topic around theory of trade offs that you said, because I let it go. But as soon as you mention optimization, I have to bring it back because it comes back exactly here. And it also brings back this question you have that markets can do a good job with the what was the how, but not the what, which is the is odd distinction that comes up in science, right? Yes, it is. science can do a good job of what is but not what ought, which means Applied Science, ie technology, ie markets can do a good job with make with changing is, but not in the direction of ot. And so that is ethics, which is to be the basis of jurisprudence and law. That's exactly why you bring those things together. The and it's because is, is measurable, third person, measurable and verifiable, repeatable, it's subjective. Its objective, right? Whereas ot is not measurable. In a, you can do something like Sam Harris does more landscape and say it relates to measurable things. But it doesn't relate to a finite number of measurable things. There's a girdle proof that whatever finite number, there are some of the things that we end up finding later that are also relevant to the thing that weren't part of the model that we were looking at. And so the thing that is worth optimizing for, when you talked about the blue and the fast would be part of the same thing, the thing that is worth optimizing for is not measurable. It includes measurables, but it is not limited to a finite set of measurable so you can run optimization theory and have an AI optimize everything for us.

Bret 1:59:16
Yeah, I agree, you will have a long list of characteristics that you can measure. And as you go from the most important to the least important, you'll eventually drop below some threshold of noise where you're not noticing things that contribute. So yes, it's you've got a potentially infinite set of things that matter less and less and you will inherently concentrate on the biggest most important contributors up top and that's natural. It's a it's an issue of precision at some level, but one that we shouldn't convince ourselves that we're solving the puzzle completely at a mathematical level. an engineering solution is not a complete mathematical solution.

Daniel Schmachtenberger 2:00:00
Right. Okay, so now I'm coming back to the waxing mystical thing. And I don't think it has to be thought of that way. I don't. I think the way Einstein was doing it and he says, spinosus, God is my God, I'm happy to do it that way. So the first verse of the Tao de Ching is the Tao that is speakable is not the eternal doubt, right? The optimization function that is optimizable, within narrow AI is not the thing to optimize for is a is a corollary statement. And, and the Jewish commandment about no false idols is that the model of reality is never reality. So take the model as this is useful. It's not an absolute truth, the moment I take it as it's an absolute truth, and I become some weird fundamentalist, who stops learning who stops being open to new input, and an optimizing the model where the model is different than reality, I can harm reality, and then defend the model. So I always want to hold the model with this is the best we currently have. And in the future, we'll see that it's wrong. And we want to see that it's wrong, we don't want to defend it against its own evolution. And so what we're optimizing for, can't be fully explicated. And that's what wisdom is, wisdom is the difference between the optimization function and the right choice.

Bret 2:01:11
I love this. This is, this is great. Obviously, it dovetails with the basic sense of what metaphorical truth is, and the recognition that actually metaphorical truth isn't something that applies to religious style beliefs. It's actually the way we do science. Also, you know, we have approximations. And you know, things get ugly when people forget that that's what they're dealing with. Right, and they start really treating it as the object itself. Very important example, in my field, is the instantiation of the term fitness. Right, which, in most cases has so much to do with reproductive success, that we actually just synonymous the most of the time. And we speak as if they're interchangeable, which is great, except for all those cases where they go in opposite directions, which we are perennially confused by. And so anyway, sooner or later, I will deliver some work that will take the cases that we can't sort out because we've missed defined fitness and forgotten that it was a model in the first place and shows how you would solve it differently if you defined fitness in a in a tighter way. But story for another day. All right. So where should we go? You, you were on a roll.

Daniel Schmachtenberger 2:02:38
So you'll see conversations from really smart people like Nick Bostrom, and Max Tegmark and whatever have because of the collective action problem, and the multipolar trap race to the bottom. And yet, because of the complexity of the issues that we face, that are beyond what the smartest person could manage by a lot, is the only answer to build a benevolent AI overlord that can run a one world government because it can process the information to make good choices. So as you can guess my answer is vigorously No. Yep. Not just because I think the optimization function that it would run, no matter how many variables would end up becoming a paperclip Maximizer. But I think its own existential risks are bound up in that process. These guys not know this. But it's easy to pick solutions like that compared to the other ones that seem maybe even more likely to go terrible. So then we say, okay, we don't want a one world government run by any of the people we currently have. And we also don't want separate nations where any of them to defect lead everybody into a race to the bottom. So that means that they have to have rule of law over each other because they affect common spaces. So how do you have rule of law over each other without it being one world government and then capture oppression or chaos at various scales? And the only answer is the comprehensive education enlightenment of the people that can check those systems. Now, obviously, the founding of this country was fraught with all the problems that we know of now in particular, and it was still a step forward in terms of a movement towards the possibility of some freedoms from the feudalism it came from. And so I, I find the study of the foundation of the theoretical foundation of it meaningful to what we're doing right now. And famously, there's this quote from George Washington where he says something to the effect of I'm going to paraphrase it. The comprehensive education of every single citizen in the science of government, should be the main aim of the federal government. And I think it is fascinating. So Science of government was his term of art and science of government meant everything that you would need to have a government have formed by the people which is the history, the social philosophy, the the game theory and political science and economics as well as the science to understand the infrastructural tech stack and whatever, right? The Hague alien dialectic the Enlightenment ideas of the time. But the number one goal of the federal government is not rule of law. And it's not currency creation. And it's not protection of its borders. Because if it's any of those things, it will become an oppressive tyranny soon. It has to be the comprehensive education of the people if it has to be a government of formed by the people. Now this is the interesting thing. Now remember, I wanted to go comprehensive education of the people as a force is something that makes more cemetery possible. cemetery of power possible, it's increasing people's information access and processing is a cemetery increasing function. So every one who has a vested interest in increasing asymmetries has an interest in decreasing people's comprehensive education in the science of government. And so now let's look at the education changes that happened following World War Two in the US. There is a theory, there's a, there's a story that I buy that

Daniel Schmachtenberger 2:06:29
the US started focusing on STEM education, science, technology, engineering math super heavily, partly because it was an existential risk, because look what happened with the stem that the Germans did. And now we know that a lot of the German scientists that we didn't get an Operation Paperclip, the Russians gotten Sputnik. And so it's an existential risk to not dominate the tech space. So we need to really double down on STEM and we need all the smartest guys, we need to find every von Neumann and Turing and find in there is all the smarter you are, the more we want to push you into STEM, so you can be an effective part of the system. That's part of the story. But also the thing that Washington said, the education and the science of government, we started cutting civics radically. And I think it was because social philosophers of the time like Marx were actually problematic to the dominant system. And I'm not saying that Marx got the right ideas, I'm saying, the idea of, Okay, we have a system, where let's have the only people who really think about social philosophy being the children of elites who go to private schools, who learn the classics. And otherwise, let's have people not fuck the system up as a whole, but be very useful to the system by becoming good at stem. I think this is a way of being able to simultaneously advance education and retard the kind of education that would be necessary to have a self governing system.

Bret 2:07:49
That's fascinating. That's fascinating, because of course, if you have the elites, effectively in charge of governance, they can do exactly what you would imagine, the elites would hope for, which is to govern well enough that the system continues on no matter what, but to continue to look out for the distribution of wealth and power and make sure nothing up ends it right, they'll do it, they won't even realize necessarily that that's what they're doing. I also love the fact you know, George Washington is one of these characters who, it's very easy to misunderstand how good he was because he, you know, he wasn't the most articulate founder or in, you know, classical terms, the smartest founder by far, on the other hand, an awful lot of wisdom buried in George Washington. And this idea of, you know, ultimately, he was looking very deeply into the future, potentially, to understand why the education of the populace would be effectively synonymous with the job of government. And it's not because the purpose is the education, but it's because that's the only hope that a democratic system will spit out the kind of solution that you want it to generate. Which is, I don't know, it's a very, it's a very interesting analysis. So it raises something else here, which is on my list of notes are rising, which is I noticed this pattern all over the place. There's a state, which is awesome, very powerful in terms of what it can do. But it's fragile, and so it falls apart. Right? In other words, we will never have a better system, as far as I can tell than science for figuring out what's true and what is possible. So it's the most capable state there are measures by which it is the strongest state, but it is also terrifically susceptible to market forces. In fact, it can't be in the same room. with them, right? So we could look for many examples of this where something marvelous, requires very careful arrangement of conditions in order for it to survive. And I'm wondering what you make of that in light of this discussion? I guess it's not hard to make an argument for why that those two things go together capacity and fragility. But what are we to do about it going forward, because surely, we're trying to build these states, but do so in a robust form.

Daniel Schmachtenberger 2:10:35
They go together because of synergy. Which is he, you have properties that none of your cells on their own have you as a whole, there's a synergy of those cells coming together that creates emergent properties at the level of view as a whole thing. But if I run all the common tutorial, possibilities of a way of putting those 50 to 100 trillion cells together, very few of them produce the synergy view, there's most of them are just piles of goo. Yeah, right. And so it's a, it's a very narrow set of things that actually has a very high synergies, and it's a lots of things that are pretty entropic. And entropy is also obviously easier I can, I can take this house down in five minutes with a rubber ball, but it took a year to build, yep, I can kill an adult in a second. But it takes 20 years to grow. And so this is why the first ethic of Hippocrates, and there's so many ethics systems is first do no harm, then try to make it better. But first, you know, harmony, if you can succeeded at the maintenance function, then you can actually maintain your progress functions.

Daniel Schmachtenberger 2:11:40
And come back to where you were going with that? Well,

Bret 2:11:51
so here's here's what I'm after. I agree with your basic entropic analysis that it is easier to destroy than to build the number of states that work is vastly exceeded by the organization of the same pieces that don't. But what I'm wondering about is, is there in effect, one has to be able to build a system that is resistant to that, in other words, and life does this right, living creatures managed to fend off entropy beautifully, and the fact we need a governmental structure that has that same trick? And we haven't seen it yet? And the question is, unfortunately, I fear that it is almost a prerequisite that if you build the capable structure, and you haven't built the thing that protects it first, then it will be captured before the wisdom develops to preserve it against that force.

Daniel Schmachtenberger 2:12:58
And now I remember why I use the analogy of the body. What I'm going to say here is wrong. So let's just take it as a loose metaphor. Let's take in the body that the closest thing to top down organization is neuro endocrine system. But there's a bunch of bottom up that is at the level of genetics and and epigenetics and cellular dynamics and whatever and that there is a relationship between the bottom up and top down dynamics. Well, obviously, I can take a cell out of a body and put it in addition, it has its own internal homeo dynamic processes, it's dealing with entropy on its own, that they don't need a top down neuro endocrine signal for how they do that. So let's say we tried to make a perfect top down neuro endocrine system, and the cells had no cellular immune systems or redox, signaling homeo dynamics or, or anything else, you would die so quickly, right? There is no way to have a healthy body at the level of the organization of all the cells if the cells are all unhealthy. And that's the comprehensive education of the individual thing we're talking about. Can you make a healthy system of government as a system? Can you just get the cybernetics right? With that is separate than that which develops all of the individuals and the relationships between them? And the answer is definitely not.

Bret 2:14:16
Okay. Agreed. But then here's the problem that I'm I'm trying to articulate. Okay, so we agree that the cells have to be coherent in and of themselves, that there has to be a fractal aspect to this, this organization of things across many scales from the individual up to the body politic. But if it is true, that the key to making that work is that individuals, which are analogous to cells here, have to be educated in the nature of governance, the theory of governance in order for this to work, how would they end up that way? Well, they would end up that way. Because governance will have created the conditions that would cause that education. So are we not now saying that what is necessary in order for the system to function is that the system is already functional in order that it can generate the conditions necessary.

Daniel Schmachtenberger 2:15:15
Now there's no hole in the bucket situation, there is a recursive situation between bottom up and top down dynamics. And so let's take the classic dialectic that relates to right and left. It's not the only one of individual and collective for a moment and say, okay, fundamentally, the right is more libertarian individual, pull yourself up by your bootstraps, we want to have advantage conferred to those that are actually doing their conferring their own advantage. And doing well. And then the left model, the more socialist model is, yeah, but people who are born into wealthy areas statistically do better than people who were born into shitty areas in terms of crime and education and access to early health care and nutrition and all those things. And you can't libertarian Lee pulled yourself up by your bootstraps as a infant or a fetus. And so let's make a system that tends to that well, but then the right would say, but we don't want something like a welfare state that makes sure the people that just meets their needs for them and orient them to lay on the couch all day and do TV and crack. Okay. I think it's, I think it's mind bogglingly silly that we take these as if they are in a fundamental theory of trade offs, as opposed to a recursive relationship that can be on a virtuous cycle. What we want to optimize for is the virtuous cycle between the individuals and the society. So that do we want to create social systems that take care of individuals, but make shittier people? No, do we want to create social systems that condition people that have more effectiveness and sovereignty and autonomy? Yes. And do we want to condition ones that in turn add to the quality of society? Yes. So if we don't want to make dumb social systems, right, so a social system that is more welfare like is much dumber than a social system that provides much better health care and education, and orientation towards opportunity for advancement rather than towards opportunity towards addiction cul de sacs. And so we already have some people, all the listeners of your show, I think we already have some people who are trying to educate themselves independent of not having a government that is doing that. That and this is why I say it has to start at culture before state or market, it has to boot in that direction. So those people can start to work together to say, how do we influence the state, and to start to then influence better education for more people better media and news for more people? And how do we influence it to affect market dynamics where the market dynamics are more bound to the society well being as a whole rather than extractive.

Bret 2:18:21
I like this, because we actually do see this dynamic, we see people actually seeking out nuance, even though we're told that they won't do it. And so the other thing we're seeing is, for various reasons, including COVID, the absurdity of the educational system that we have is being revealed in a way that it never has been before so many more people are recognizing that school will flat out waste your time if you give it that opportunity. And therefore, they have more licenses than ever to seek out high quality insight and exercises or whatever and to discount the value that we are assured comes along with a standard degree. etc. So yeah, I'm favorable to this idea. But

Daniel Schmachtenberger 2:19:10
here's also the you just said that's interesting is okay, so George Washington's, quote, comprehensive education of every citizen science and government, well, how can we afford that when most of them are going to be laborers? Because them having a strong background in in history and Political Science and Social Science and the infrastructural tech stack, does that help them be better farmers? Not really, it helps them be better citizens and government but not better farmers? And so can how do we afford to pay for all that additional education? And how do they maintain that knowledge when they're just engaged in the labor type dynamic? And so this is why the children of the elite who are actually going to become lobbyists and senators and whatever, go to that private school and get that education. Well, now we have this AI and robotic technological unemployment issue coming up, and it's definitely Coming up, right? Well, the things that it will be obsoleting. First are the things that take the least unique human capabilities, because those are the easiest to automate. So labor type things. So easy, either this is an apocalypse, that just increases wealth inequality and everybody's homeless, in fact, or on the absolute minimum amount of basic income. So the elites can keep running the robots as serfs rather than the people, the serfs and just took the people up to Oculus with a basic income, so they don't get in the way. Or this actually makes possible, a much higher education of everyone so they can be engaged in higher level types of activities. Yeah,

Bret 2:20:45
yeah, no, I agree with that completely. And I also agree, you know, we should make sure people understand. I mean, I think it was very clear the way you said it, but we are headed for a circumstance in which a shift in the way the market functions, and what it requires is going to cause an awful lot of people to be surplus to it all at the same time. And that can only play out in a few ways. None of them are good, if we don't see it coming and plan for it. It's coming. It's not the fault of the people who will be obsoleted. And so in any case, yes. When you make sense,

Daniel Schmachtenberger 2:21:24
you mentioned you look at COVID. And look at how many small businesses shut down, and how much unemployment happened, and then how much the market rallied because six companies made all of the money of the market. And if you take those companies out, the entire stock market is down. But it's cap weighted. And you basically have network dynamics Metcalf law dynamics, creating winner take all economies, where you have one winner per vertical. The wealth consolidation, the wealth inequality has progressed so rapidly, that all the that the measurements of GDP and market success, and the measurements of quality of life are totally decoupled or moving in opposite directions in really important ways. When you combine how intense that is, and that, of course, the forces with the most money are the hardest to regulate, because they have the best lawyers the ability for offshore accounts and for lobbying and whatever else. So how do you do anything about this, combined with the fact that the debt to GDP ratio is unfixable, you realize that a reset of our systems will happen because this system cannot continue. And we can either do a proactive one, or we get the reactive one. And the reactive one worse,

Bret 2:22:41
the reactive one is going to inherently be arbitrary, and therefore much more violent in every sense of that term. And so yes, you are programming some kind of a, unfortunately, none of the terms that one would like are still available to us, because great reset has obviously been branded in, in somebody's interest. But yes, we need some sort of a reboot. That takes heed of this dynamic and sets us on a path where it doesn't turn into a catastrophe or it doesn't turn into a spectacular win at everybody else's expense for some party or other. And unfortunately, of course, we circle back to an early part of this discussion, convincing people of the hazard of this the essentially the certainty that something of this sort will happen if we do nothing, that we must do something that that something must be coordinated, that you can't pass it through your inherited lens of is this left leaning is this right leaning is this for my team is this against my team. convincing people of that is extremely difficult in this environment, because for one thing, everything we would do to convince passes through these, these platforms that if they haven't flexed their muscle, yet, as soon as we start talking about what would need to be done, to save civilization in ways that they can recognize it, they will find ways to oppose it.

Daniel Schmachtenberger 2:24:22
And you've had this conversation on here before that. Let's say we can we look at a particular group and we can predict how they're going to respond to something we're going to say with quite high accuracy. So we can take a particular woke SJW group and if we have a conversation of a certain type, we can predict it they'll say, oh, that thing you're calling dialectic is giving platform to racists when you should be canceling them. Therefore you're, you know, racist by association or whatever. You can take a cue anon group and predict that they are going to say that because we talked to someone that was four steps away from Epstein in a network that we are probably part of the Deep State cabal of pedophiles, or whatever it is. And to the degree that people have responses that can be predicted better than a GPT three algorithm, they can't really be considered a general intelligence. They are just a medic propagator. They're taking in memes rejecting the ones that don't fit with the meme complex taking in the ones that do fit and then propagating them. And I think people should, I think if people think about that they should feel badly about not being someone who's actually thinking on their own and being highly predictable, mimetic propagator, and be like, I would like to have thoughts that are not more predictable than a GPT three algorithm. I would like to know what my own thoughts about this are? And in order to know what my own thoughts about it are, do I can I even understand and inhabit how other people think all the things that they think that so that's, that's one thing, because it's not only going through the filters like Facebook, it's going through the filters of the fact that people have these mimetic complexes that keep them from thinking. And so the cultural value of trying to understand other people so that we can compromise, because politics is a way to sublimate warfare, right? And if you don't understand each other and compromise, you get war, and the people who are saying, yes, let's bring on the war, they're just fucking dumb. They just don't understand what war is actually, like they haven't been in it right?

Bret 2:26:43
Well, I think you have brought us to the perfect for last topic here. Now, of course, I'd like this conversation to go on, and we should pick it up at another date. But the point you make about, if we can demonstrate that we know what you're going to say, then it isn't a thought worthy of a human, right? If we can predict you, and it's not by virtue of us, having modeled some beautiful thought process of yours, it's because your thought process looks like that of, you know, an indefinitely large number of other people who are totally predictable. And that's nothing you should be comfortable with. I think we this goes back to the question I asked you at first, which is, when you engage in what I would call independent first principles thinking, you immediately run into challenges that somebody who's not deeply involved in such a thing doesn't Intuit, right? And so I'm imagining a person, somebody who is decent, who has compassion has all of the basic capacities you would hope they would have who has fallen into one of these automatic thought patterns. And I'm imagining, you managed to sit down with them and show them that their thought pattern is automatic and totally predictable, and therefore nothing that they should be comfortable with. And let's say that they walk out of the room, and they start behaving differently. And they start thinking for themselves, they stay awake, right? Well, they're going to run into some stuff, because they are of course going to end up landing on some formulations, that as soon as they say them out loud, are going to get them punished. Right, that is inevitable. Now, those of us who live out here, learn how to say things in ways that sometimes the punishments don't stick, we learn where they are best stated, we learn what we shouldn't say yet. But all of this speaks to what I think is it's not we don't live in an authoritarian state. But we live in a state in which thought is policed as if we did, right not perfectly, but enough that one who wishes to escape from the accepted, the sanitized narrative has to be ready for what happens next. And that's something that is it's very hard to generate that. In other words, it's a developmental process that causes you to learn how to navigate that space. So somebody who just simply recognizes I don't want to be an automaton, and I'm going to start thinking for myself, if their next move is to start thinking for themselves and speaking openly about it. What comes back next to something for which we don't have a good response.

Daniel Schmachtenberger 2:29:38
Earlier you said when you were defining near the beginning of our conversation, what you meant by independent thinker is someone who wants to go where ever the facts and information that are, well verifiable actually leave them. I would say that there. There's something like this. spirit of science, which is a reverence and respect for reality, where I want to know what is real and be with what's real more than I want to hold a particular belief, no matter how cherished or whatever in group it, I'm a part of in the uncomfort of not belonging with the group. If I want to belong with anything, I actually want to have a belonging with reality first, and of belonging with my own integrity. And then with those who also share that. And the other belongings that I give up, I don't stop caring about those people, I care about them still. But I don't necessarily care about their opinion of me enough that I'm willing to distort my own relationship with reality.

Bret 2:30:43
Alright, so here's the question, I want to ask about this. And I'm basically trying to surface some part of my own process in order to figure out what it is, can it be improved? Can I teach it to others to the extent that it works? There are. So I was on Bill Maher with Heather, last Friday. And I said something that got an awful lot of pushback online, which I knew was coming. I said, he asked if I thought the probability that COVID-19 was the result of a lab leak was at least 50%. And I said something quite honest and shouldn't have been new to anybody who had been paying attention to my channel, which was that I had said back in June, that I thought the chances are at least 90%. Now I can imagine that that number would be shocking to many people. But I also know that were I in their shoes, I would process it this way. I would say, Alright, this person seems intelligent. I don't know of a conflict of interest. That numbers way off of what I would calculate. Therefore, I need to file this as a flag. Do I not know something? Maybe the person has a conflict of interest? And that explains it. But if it's not that, how have they arrived at a number that is so far off of what I would calculate? And what does it tell me? In other words, I would become agnostic at that moment, rather than go on the attack.

Daniel Schmachtenberger 2:32:18
People don't give enough benefit of the doubt to people who agree who think differently, and they give too much trust to those who think the same,

Bret 2:32:25
right. But then here's the the place that the thought goes. So is it true that if somebody intelligence says something that is completely inconsistent with my model of the universe, that I will inherently give it enough credence to look at it? It's a tough question. Because if I if I try some test cases, if you told me that you believe that there was a strong chance that the Earth was flat, okay, that would throw a huge error for me, right? Because I know, a that I've checked, right? In fact, I have years ago and several times said, What are the chances there's anything that these flat earthers, that they're not just a joke, and then it's a trivial matter? To find out what you need to know from your own experience that is inconsistent with that possibility? And so the answer is okay. I'm not going to spend too much time checking with it. Right? Then we get to, is the moon landing fake? Right? This one is tougher, right? It's tougher, because when you look at the actual evidence that people are motivated to hypothesize that the moon landing is fake. There are some things in it that are hard to know, I don't offhand know what the explanation for them is. So anyway, my point is, there are some ideas, I wouldn't be shocked at all to find that you believe there's some ideas, I would be shocked. so shocked that I would imagine you're kidding, or you've lost your mind, or I don't know what. And so we all draw that line somewhere. And I guess my point is, I think almost everybody, even very, very smart people who don't happen to be experienced in first principles, independent thinking, draw that line somewhere, that creates a fatal error when independence is experimented with. Right? That the number of things that you know it is the matrix in some sense, once you start experimenting with what would I conclude if I was independent of all incentives, and I just went based on the evidence and I gave everybody a chance to articulate their position. What comes back is so jarring that most people are driven back into conventional automatic thinking, because the the frightening aspects of what what they get in response are enough to drive them off the instinct.

Daniel Schmachtenberger 2:34:53
Yes, okay. God, there's so much in here. That's really good. The thing about the flat earth is that it is the hypothesis is formally falsifiable.

Bret 2:35:09
And the alternate hypothesis even by an individual.

Daniel Schmachtenberger 2:35:12
Yes. And it's the, the alternative hypothesis is formally verifiable with the best methods that we have with the highest confidence right now. And now one thing I would still say is interesting is, I know many people who refer to flat earthers as the moniker of maximum stupidity who cannot do the Copernican proof. So they take as an article of faith that the earth is round, but they actually don't know how to drive it have never tried. And so then they also move to taking as an article of faith, similar things that don't have the same basis. So if so, does someone even understand what falsifiable and verifiable mean? Does someone have a basis for calibrating their confidence margin? Because if, if I start to talk about the moon landing, or then I go a little bit further and talk about long term, autoimmune effects or epigenetic drift, or whatever that come from a vaccine schedule of 72 vaccines together? Is the standard narrative, falsifiable or verifiable is the alternate narrative falsifiable in the way flat earth is no. So the fact that we put flat earth and anti Vax in the same category is a intellectually dishonest, bad thing to do. And but the fact that most people don't even know how to do verify or falsify. And so like, with the lab hypothesis, when you come to 90%, I'm guessing you have a process for that. What I would say is I haven't studied it enough to put a percentage because I don't have enough Bayesian priors to actually come up with a mathematical number. What I would say is, I consider the idea of it coming from a lab and some kind of dual function, game data function, research, dual purpose gain function to be very plausible. And I have seen nothing that falsifies that and the few attempts that I saw early to falsify it were theoretically invalid to me. Now, to be able to go from plausible to a probability number, I would need to apply different epistemic tools than I have already applied.

Bret 2:37:22
Well, wait a second. I'm not sure that that's the case. Because the, to me as a theoretician, there is a hypothesis. The there are multiple hypotheses. One is the virus escaped from a lab unmodified. Another is that it was enhanced with Ghana function research, and then it escaped. Another is that it was weaponized and deliberately released all of these things. Each of them is a hypothesis. Each of them makes predictions and they are all testable. Now, I am not required to have any guesses as to which one will turn out to be correct, nor an assessment of how probable it is. It is natural to have a guess. But the two things function independently, right. As a scientist, I am obligated to treat a hypothesis by the formal rules of science. I know what they are, I know how they work. And therefore I know at what point it's going to be falsified any one of them. And what would be necessary for one of them to become a theory that is to say, for all of its challengers to fall? Now, I can also say, look, if I had to bet yours, right, put my money, but I'm not I'm I happened to be a scientist who would be placing a bet, but my bet is not a scientific bet.

Daniel Schmachtenberger 2:38:47
So we're, we're aligned clarification. Agreed.

Bret 2:38:50
Yeah. Okay, good. So then,

Daniel Schmachtenberger 2:38:52
that that is that is my hunch that I didn't come to that number through a actual Bayesian or other kind of mathematical process. But if I was actually trying to formally give my my percentage basis, I would go through some epistemic process and then work on now if I had to make a consequential choice based on it. The more consequential the choices, the more process I would want to go through to calibrate my confidence of it, because the more problematic would be for me to be wrong,

Bret 2:39:23
right. Okay. So that that all makes sense. But the the ultimate question here is, given that we can see, we want people not to behave in an automatic way, in a way that is below the nature of human cognitions capacity to think and to react. But we also know that when people experiment with that, under the current regime, it is not that they will produce conclusions that are different than they would otherwise produce, say them to their friends, and their friends will say, Oh, that's interesting. I didn't realize you think that their friends will say Oh, my God, I can't believe you're one of them. Right? And that that thing is so powerful that it is artificially depressing the degree of independent thought, because anybody who has experimented with it is likely to have effectively, you know, touched some third rail, and retreated as a response. So we don't know if

Daniel Schmachtenberger 2:40:22
there's a failure mode on both sides. There's a failure mode of not creating artificial constraints where we don't explore the search space widely enough. Which is the one you're mentioning. There's another one of exploring the search space without appropriate vetting and jumping from hypothesis to theory to fast, yes. And those two are reacting against each other. Right? There are people who say, because it's plausible it is they jump from hypothesis straight to theory without proof. And then they believe wacky as shit, yes. And they insist that it's true. And then people over here are like, Wow, that's really dangerous and dreadful. And anything that looks like that I'm going to reject offhand. And similarly, people over here believe standard models that end up getting either captured or at least limited. And people over here react against that. So this is another place that I would say the polls are driving each other both to nonsensical positions? Well,

Bret 2:41:17
yes. And the way that works in practice is, there's a team that, in principle knows that it is in favor of doing the analysis, but it does not believe itself capable of doing the analysis. So effectively, it signs up for the authority of those who claim to have done the analysis and in principle, have the right degrees or whatever. But then we run into this thing, which goes back to something you've said in several places in this discussion, which has to do with the bias amongst those involved in certain behavior. In other words, if you're an epidemiologist at the moment, or a virologist, there's a very strong chance that you believe the lab leak hypothesis is at stands a very low chance of being true. But you also very likely have a conflict of interest, you may be directly involved in the research program, that would have generated COVID-19. Or you may simply be involved in social circles in which there is a desire not to have virologists responsible for this pandemic, and therefore, there's a circling of the wagons that has nothing to do with analysis. But either way, the tendency to converge on a consensus is completely unnatural. And those who are trying, who earnestly are trying to follow science and up following consensus delivered by people who claim the mantle of science while not doing the method, and that is a terrible hazard.

Daniel Schmachtenberger 2:42:56
Yeah, yeah, I agree. And there's one step worse, which is the thing that we mentioned earlier, which is you can do the method, have the all of the data coming out of the method be right and still have the answer be Miss representative of the whole because you either studied the wrong thing, or you studied something too partial. And so this question of what is worth trusting, comes up again and is okay, I, I don't want to defect on my own sensemaking to just join the consensus, so that I am not rejected. At the same time, if everyone is sure that I'm wrong. And I'm sure that I'm right. I should pay attention to that, right? Because very possibly, I have a blind spot, and I'm a confused narcissist. Every once in a while, they are all in an echo chamber, and I'm actually seeing something and it's it both can be the case sometimes. So you're like, Okay, do I always stick to my guns? Or do I always take whatever the peer review says? Neither This is again, the optimization function, isn't it? wisdom ends up being a I don't know the answer to this trolley problem before I get there. Right. So what I have to say is, is the basis by which the other people all agreed that you were wrong, deliberative, and methodological and earnest and free of motivated reasoning, does it have a group motivated reasoning that's associated with it? Are there you know, clear blind spots in the thing you're thinking? So I don't think there's an answer to the what actually is right there. There is no methodology. It's the doubt it's eternal is not that the speaker is not the eternal doubt of the methodology that's normalizable is not the thing that reveals the Dow right, like ultimately, you have to end up adding placebo at a certain point and then double blinding and then randomization. The methods have to keep getting better because There's always something in the letter of the law that doesn't get the spirit of the law. And in the letter of the methodology that doesn't get actual science, right,

Bret 2:45:08
right. And in fact, so a couple things here, one, there's a part of the scientific method, which is a black box, there's a part that actually, I believe literally cannot be taught. Right? It is the part where you formulate a hypothesis. Right? That is a that is a personal process. If I taught somebody to do it my way that I don't think they do it very well, right? So the point is, that's something that you learn to do, through some process that is mostly not conscious, hard to hard to teach, and hard to discover. But everybody who does it, well does it in some different way. And so at that level, even just saying, Do the method is incomplete, because not everybody can do the method. See, there was something else. Oh, yeah, there was there was a missing thing on your list, I realized you weren't trying to be exhaustive, but there was a missing thing on the list of possible reasons that you could come up against a consensus and still be right, even if you're the only person who disagrees. And it has to do with the non independence of the data points on the other side, based on let's say, either a perverse incentive, or a school of thought having won out and killed off all of the diversity of thought over some issue that turns out to matter. And these things can very easily so I would say yes, if you always think you're right, and when everybody's against you, they're wrong, then yeah, narcissism is a strongly likely reason. On the other hand, it is, as you point out with Tesla and their competitors, sometimes you find that a field or an industry is easy to beat, that there's something about them, that is, you know, maybe economically very robust, but with respect to their capacity has become feeble. And this is true again, and again, in scientific fields that scientific fields, go through a process where they, a school of thought, delivers handsomely on some insight, it wins the power to own the entire field, that insight runs its course, diminishing returns, sets in, it stops delivering anything new, it doesn't give up the reins and hand them over to somebody else, because there's no mechanism to do that. So the people who have the school of thought that's already burned out its value, stick to their, you know, their power. And that means that the field is wide open, to be beaten by an outsider who just simply isn't required to subscribe to whatever the assumptions of the school of thought are. And that happens so frequently, that there is this, it's artificially common that you have the experience, if you think independently, and you know what you're doing, that you'll disagree with just about everybody. And they'll actually turn out to be wrong, because they're proceeding from a bad set of assumptions.

Daniel Schmachtenberger 2:48:13
So I think this is actually one of the most interesting applications of blockchain or decentralized ledger technology is this idea of an open science platform. So imagine, every time someone did a measurement, the fundamental measurement, it had to be entered into a blockchain. And then the other places that independently did it was entered into blockchains was uncorruptible. And then the, the axioms and kind of logical propositions get entered in, and then the logical processes of whether I'm using an inductive or deductive or what abductive process gets put in. And then we get to kind of look at the progression of knowledge, then at any point, we come to realize that a previous thing and there was wrong, some data was mis entered or a hypothesis is proved wrong. Now we can come back to that point and look at everything downstream from it and re analyze it. Of course, you still have the Oracle problem of the entry in the first place. So if I'm doing motivated science, and I get some answers I don't like and I can hide them and not enter them, then that will happen. So you still have to have then the proper entry into the system. But this addresses something with the integrity of science and also the integrity of government and government spending and the capture of market forces of the regulators rather than the regulators being able to regulate the market is we only know when the fucked up thing happens if we can see it, and which means that everyone who wants to do something asymmetric or predatory has a maximum incentive for non transparency. So certain kinds of uncorrupt stability and transparency are very interesting and what they can do towards that.

Bret 2:49:50
Interesting now this actually comes back to something I wanted to raise earlier, but didn't get to it, which is I started out very focused on this stainability I believe sustainability is something that the system, you can't, you can't measure to finally, if you measure to finally then sustainability becomes an absurd block to progress because you can't dig a hole in your own backyard because you couldn't dig a million such holes. But if you relax the system so that you're measuring processes that actually potentially matter, sustainability has to be a feature of the system long term, right? It doesn't have to be the feature the system in any given time period. But overall, it has to net to a sustainable mode.

Daniel Schmachtenberger 2:50:39
I wouldn't say a system has to be sustainable, I would say the meta system or increasing orderly complexity has to be sustainable. But that might mean a system intentionally obsoleting itself for a new better system. Okay,

Bret 2:50:51
I accept that. But what I've realized down this road is that the system actually, or the set of systems or the metal system, however you want to describe it needs a failsafe, which I call reversibility. Right? So the point is, if you set the goal of sustainability, and you say, well, we have to measure things that matter, sooner or later, you're going to fail to measure something that matters, and you're going to deal with it unsustainably. And at the point that you figure it out, it's going to be too late. So my point would be, and you know, this is a tough one, people don't like the implications of this, if they understand it. But any process that you set in motion has to be something you could undo if it turns out to be harmful in a way that you didn't see coming. Right. So that is to say, you can alter the atmosphere, carbon dioxide is not poisonous, right? The changes in concentration that change the degree of heat trapping, are not terribly meaningful to the well being of living creatures. But at the point, you discover that the heat trapping is going to massively change the way the atmosphere functions and the oceans, etc, etc, you have to be able to undo it now undo it means you could change the concentration back to what it was. Now, what this would mean in practice, was that you would have to slow the process of change down such that you scaled up the process that would reverse the change in proportion. Now, if you imagine all of the disasters that we have faced all the ones I named up top and all of the other ones that look like it from, you know, Fukushima to Aliso Canyon to financial collapse of 2008. And you imagine that in proportion to the process that went awry, we had scaled up the reversal process so that it was there, if we needed it, right, we would have been in a very different situation, because a the process would have run away much, much slower and be the tools to undo it would have been present and ready. Oh, before you respond to that, I do want to say that the only way that that would work is if it was over the entire system. In other words, if one nation, for example, were to decide that it had to adhere to a standard of reversibility, while other nations weren't restricted in the same way you didn't, you'd get a tragedy of the commons where the atmosphere or whatever other resource would ultimately be destroyed by the nations that didn't participate in that system. And the nation that was most responsible would pay the cost of building a reversibility system that wouldn't work in the end. But other than that, I think the principle makes sense. What do you think

Daniel Schmachtenberger 2:53:41
there's some thing like sustainability, having a consideration like reversibility as one of the factors to inform choice making. And that is a valuable consideration, and that it doesn't matter at all if we don't have collective coordination capacity to be able to make the right choices period. So yes, agreed. Now, regarding reversibility, I think reversibility is a valuable consideration. That is

Daniel Schmachtenberger 2:54:17
impossible in important ways. But it's still an important consideration. So can I decrease the amount of co2 in the atmosphere if we realize we need to? Kind of Yes, but the co2 in the atmosphere went up, along with a lot of mountaintop removal, mining for coal, and a lot of species extinction in the process. A lot of people who died over wars for oil can I reverse and get those dead people back and those extinct species back in those pristine ecosystems back? Nope, they're gone. And then also reversibility over what timeframe will new old growth forests come back 1000s of years from now. Sure does that timescale matter if I ever extinct a species, is that reversible? Does every species matter? What about killing an individual element within it, you know, so it's like, I can only think about reversibility on very narrowly defined metrics. But the thing that harms that one metric has lots of other effects simultaneously. And so we have to understand the reversibility by its by itself is an oversimplification, because we'll always be thinking upon metrics that are subsets of all that's affected.

Bret 2:55:33
Yep, I agree. It is. A is a oversimplification, as is sustainability. But my sense is that you have to instantiate it in some way in order for the system to be safe. And I would say, if it prevents you from removing mountaintops, as long as it prevents everybody else from removing mountaintops, it's the right idea. In other words, if we are allowed to degrade the earth a little bit at a time, by removing mountaintops now and you know, drying up rivers next time, then eventually you have a world that isn't very worth living in. And I do believe that we have a moral obligation not to degrade the planet, right? That that our highest moral obligation has to be to deliver the capacity to live a complete, fulfilling human life to as many people as we can. And that means not liquidating the planet, it means a renewal process, which is the very definition of sustainability. And it's inconsistent with removing mountaintops. Now, lots of species don't matter. Right? There are lots of little offshoots of species, and they can go extinct, and they do go extinct, and nobody is harmed by their doing. So which it's not the same thing as losing orchids or, you know, elephants or Eagles or whatever. So, obviously, you need to have a, a rational threshold in which you protect against against degradation and allowed degradation that doesn't have an important implication. But the question is, really, is it so compromised by those considerations that it's not worth considering? Or is it rescue Abul if one figures out how to apply a threshold?

Daniel Schmachtenberger 2:57:26
So we said that one of the dialectics that defines that left and right in its most abstract form generally has to do with a focus on the individual versus a focus on society or the collective of the tribe or some kind of group. Another one is an orientation towards conservation or conservativeness traditionalist with an orientation on the other side towards progress or progressiveness. And again, these are confused all over the place. And even what we call left and right have shifted in the last, you know, few decades in a number of ways. But it's interesting here, because when you talk about reversibility, and sustainability, another synonym is conservation. What is it that we want to be able to conserve? And so the conservative principle is focused on what has made it through evolution that is valuable enough that we should conserve it and fuck it up. Yep. So interestingly, the, the people who are often called conservatives are not focused on critical aspects of conservation. But if you, you're talking about biosphere conservation, right now, oftentimes, they're talking about socio sphere conservation, the conservation of social systems. And you're saying that underneath it is the capacity for humans to thrive and have meaningful lives and relationships. And we would say that that is a function of the biosphere, the social sphere, and the technosphere and the relationship between them. And so we can say very clearly, it's the technosphere ruining the biosphere most of the time, and yet if it ruins the biosphere enough, the technosphere goes because the technosphere depends on the biosphere. So we have to learn how do we make a technological built environment that is replenishing regenerative with the biosphere. And the social sphere is another really critical and I think you'll probably actually have something to add to this I haven't thought of when I think of what the fundamental intuition of a conservative is, even if they don't articulate it like this. And the traditionalist kind of impulse which is, let's go back to the Constitution, let's go back to Christianity or European ideas or the free market or whatever it is, or rigorous monogamy whatever social structure lasted for a long time. That there there's an intuition, even if they don't formally Think of it this way logically, that almost everything didn't make it through evolution in terms of social systems. And the few things that did weren't the things that people thought would so there's a lot of embedded wisdom that wasn't understood. It was very hard earned and we want to preserve that and not break Because we think we understand it well enough, and we might not. And that fundamentally, the progressive intuition is that we're dealing with fundamentally novel situations that evolution didn't already figure out and we need innovation. And of course, the synthesis of that dialectic is we need new innovation that is commensurate with that which should be conserved. And not everything should be conserved, because some things made it through because they won short term battles well fucking up the long term whole. And so what things are worth being conserved what things are not worth being conserved? Did we understand that well enough that we didn't say this isn't worth being conserved out of hubris? And then what progress is commensurate with that, I think is a good way of thinking about that dialectic.

Bret 3:00:42
Yeah, I like it. And I think there's the flip side of it as well, which is that captured inside the biblical traditions are some bits of so basically responses to game theoretic hazards that are consistent with things we've talked about. So for example, the Christian sense that not only is the world here for humans to make use of, but that we are in effect obligated to do it. That belief fits perfectly in a world where if your population doesn't capture a resource, somebody else is going to So in other words, that belief structure travels along with a tendency to capture the resources that are available. And to the extent that what that does is it causes the exploitation of a resource, the tools with which those resources could have been exploited in biblical times, almost always left a system that would return itself to equilibrium, given an opportunity, which isn't true in the modern circumstance. So what we have is a place where there's lots of stuff that is conservative, that there's a very good and often hidden reason that we should preserve. And then there are some places where we'd actually have to upgrade the wisdom because it doesn't fit modern circumstances. And the conservation of the natural world is, I think, a clear case.

Daniel Schmachtenberger 3:02:13
Just because you mentioned this case, when, when people realize that Christian spread, largely by holy war, not exclusively, but largely, you need a religion that makes a lot of people that are willing to die in holy war because of a good afterlife. And who you can spare, right a lot a large population of people that can die in war. And Islam and Christianity both had this, they both had, Be fruitful, and multiply and proselytize. Because they both had war as a strategy for propagation of the means. So you needed numbers, whereas Judaism didn't have it, right? And quakerism and some other ones didn't, Judaism had to actually make it hard for people to join the religion, because you're not gonna lose a lot of people as soldiers, you're gonna embed yourself as a diaspora within dominant cultures and end up affecting the apparatus of those cultures. So it's interesting to think about how those different meme flexes had different evolutionary adaptations. But it's important for the reason you mentioned is that those traditions were influenced by politics and economics and war and philosophy and culture and a lot of things so you can't wholesale throw them out or keep them or like, you have to actually understand what allowed those memes to propagate and what their mimetic propagation dynamics were. And so that conservative impulse, it says the things that made it through made it through for a reason, yes, but some of the things that made it through for a reasonable keep making it through dinosaurs were around for a long time. And then they weren't right. So and as we've mentioned, evolution can be blind and run very effectively in the cul de sacs. And yet the other side is all too often, we will criticize a tradition for being dumb, when we don't understand what made it work well enough, and we throw something out that was actually worth not throwing out. So how do you do a deep enough historical understanding, to be able to decide what should be conserved and not? Is is also a really good question.

Bret 3:04:13
It's a really important question because it's it's Chesterton's fence factory effectively, right? Nobody knows what, what actually was functional and what, you know, we had no function but traveled along with it, because they were paired very closely in a biblical text. And, you know, what functioned in ways that we don't want it to function. Now, these things are all invisible, because the whole thing is encoded in myth. So it's not in there, right. So yeah, that's a huge hazard. And it's a tough one for those of us who want to build reasonably and recognize that there's an awful lot that we have to do that's novel that hasn't been accomplished before. We have to grapple with the fact that it's not like these traditions are Simply backward, some of them are very insightful and non literal. And we need to exercise great caution, caution in approaching them.

Daniel Schmachtenberger 3:05:12
Okay, so I want to come back to your three generations at least problem. It's easy to look at the nature of the problems and just assume that we are fucked. And usually to tie that to some conversation about human nature. And to say, Okay, well, we were able to figure out technology that was extraordinarily powerful to speak mythopoetic Lee the power of gods, the nuke was clearly the power of God, right? And then lots of Texans, then we can genetically engineer new species gain a function, whatever. It without the love and wisdom of gods that goes in a self terminate direction. Is it within the capacity of our nature to move towards the love and wisdom of gods to bind that power? Or are we inexorably inadequate vessels for the amount of power we have? So then I do a positive deviant analysis to look at what are the best stories of human nature to see if they converge in the right direction. And then also, where there are conditioning factors that we take for granted because they become ubiquitous, and think that they're nature. So if we, if we go back to the Bible for a moment, we look at Jews, and we look at was there a population of people that were able to educate all of their people at a higher level than most other people around them? for a pretty long time in lots of different circumstances? Yes. You look at the Buddhists, were there a population of people that across millennia and different environments, were able to make everybody peaceful enough to not hurt bugs? Yes. Across all the genetic variants, and across all of the economic factors, and whatever else, do we have examples, a very high level of cognitive development and very high level of ethical development of different populations based on cultures we do. And then we say, Oh, well, but you know, look at how well the founding fathers ideas failed here. Well, the, the comprehensive education of everyone is not in the interests of the elite that have the most power, as we mentioned. And so making it seem like that, that's an impossible thing is actually really good to support the idea that there should be some kind of nobility or aristocracy or something like that there should be elite to control because they're more qualified. I would say that we have not, in modern times ever tried to educate our population in a way that could lead to self governance, because there is no incentive to do so. Or those who had the most capacity had incentive to do something else, even when they said they were doing that. So do I think that it's possible to I think that we have examples historically of people who develop themselves cognitively and ethically enough that if we did those together, right, Buddhist Jews have where we want to talk about it. Do I think that's possible within human nature and basically untried? Yes.

Bret 3:08:12
Yeah, I love that. And I agree with you, it's dependent on something which we might as well spell out here, which is that the capacities, the difference in capacity between human populations is overwhelmingly, if not entirely at the software level, which I firmly believe I'm speaking as a biologist, I've looked at this, I will have to defend it at length elsewhere, but the degree to which it's software that distinguishes us and therefore, we can innovate tools, we can democratize tools, all of that is at our disposal. And I agree with you, it hasn't been tried. And it might be our only hope. But at least we've got prototypes.

Daniel Schmachtenberger 3:08:51
Now I will say why I'm grateful for what happened at evergreen is that you wouldn't be here doing this otherwise, and on Bill Maher, and your you and Heather, both exceptional educators. And so the fact that your tiny little niche for education got blown up so that you took this quality of education to all the people who were interested, this larger scale I'm really happy about because I have my friend, this exact thing is the thing that has a chance is a strange attractor of those who are called to a cultural enlightenment, starting to be come to come together in a way that can then lead them to coordinate to build systems that can then propagate those possibilities for other people.

Bret 3:09:33
Well, I really appreciate that. And I, I must say, I feel it as a calling as I'm certain you do. And so yes, and I also love the point that you made earlier about the fact that the audience for this really is people seeking a kind of enlightenment and community and so yes, as much as you and I both focus on existential risks. There is hope in that. Yeah. Okay, Danielle? Well, this is I think we've gone more than three hours, it's certainly been a great conversation and there are so many threads that are worth revisiting, which we should do sooner rather than later.

Daniel Schmachtenberger 3:10:18
This was super fun. I really enjoyed it. Yeah, it was.

Bret 3:10:21
So Daniel Martin Berger, where can people find you?

Daniel Schmachtenberger 3:10:27
Well, you mentioned in the beginning, we have something called the consultants project that we'll be launching soon, via a newsletter in March and then website in a few months. So tune back in on that it's a it is a project in this space, a nonprofit project that is seeking to do a better job of news with education built in. So we actually make the Epidemics we look at very complex issues that are polarized, and we make the epistemic that we're applying explicit. So we're actually teaching people how to use sense make complex situations in situ. And then if anyone ever thinks we missed any of the data or about something wrong, they can let us know and we'll publicly correct it and credit them if that's right, and etc. So. And the goal there is helping to catalyze cultural enlightenment of this type at recognizing that both education and Fourth Estate are requisite structures for open society and open society. Being rebooted has to be rebooted at the cultural level first. Right now. You can find me on Facebook, or one of those platforms or have a blog. An old blog, everything's out of date on it, civilization emerging calm,

Bret 3:11:40
civilization emerging calm. And are you not on Twitter? And does that explain how you're so clear headed?

Daniel Schmachtenberger 3:11:48
I'm not on Twitter. And I'm on Facebook, because it because of Metcalf law, because everyone is so it ends up being a useful introduction and messaging tool. But yeah, I'm I'm not part of the Twitter crew.

Bret 3:12:04
more power to you. All right, Daniel. This has been a pleasure, and I look forward to our next one. Be well, everybody else. Thanks for tuning in.

Daniel Schmachtenberger 3:12:15
Thanks

This transcript was generated by https://otter.ai